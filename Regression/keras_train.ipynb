{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "import uproot_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_arrays(a, keys, axis=-1):\n",
    "    flat_arr = np.stack([a[k].flatten() for k in keys], axis=axis)\n",
    "    return awkward.JaggedArray.fromcounts(a[keys[0]].counts, flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(a, maxlen, value=0., dtype='float32'):\n",
    "    x = (np.ones((len(a), maxlen)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(a):\n",
    "        if not len(s):\n",
    "            continue\n",
    "        trunc = s[:maxlen].astype(dtype)\n",
    "        x[idx, :len(trunc)] = trunc\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##and Professor suggests that we could use mass, classifacation for later application\n",
    "def SetAKArr(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    n_particles_ls = []\n",
    "    px_ls = []\n",
    "    py_ls = []\n",
    "    pz_ls = []\n",
    "    energy_ls = []\n",
    "    mass_ls = []\n",
    "    charge_ls = []\n",
    "    _label1 = []\n",
    "    _label2 = []\n",
    "    _label3 = []\n",
    "    _label4 = []\n",
    "    _label5 = []\n",
    "    \n",
    "    n = 0\n",
    "    for line in lines:\n",
    "        if line.startswith('E'):\n",
    "            if not n == 0:\n",
    "                n_particles_ls.append(n)\n",
    "                n = 0\n",
    "            exp_inf = line.split()\n",
    "#             _label1.append(int(exp_inf[1]))\n",
    "#             _label2.append(1-int(exp_inf[1]))\n",
    "#             _label1.append(1)\n",
    "#             _label2.append(0)\n",
    "            _label1.append(float(exp_inf[1]))\n",
    "            _label2.append(float(exp_inf[2]))\n",
    "            _label3.append(float(exp_inf[3]))\n",
    "            _label4.append(float(exp_inf[4]))\n",
    "            _label5.append(float(exp_inf[5]))\n",
    "        else:\n",
    "            par = line.split()\n",
    "            ##particle +1\n",
    "            n = n + 1\n",
    "            px_ls.append(abs(float(par[2])))\n",
    "            py_ls.append(abs(float(par[3])))\n",
    "            pz_ls.append(abs(float(par[4])))\n",
    "            energy_ls.append(abs(float(par[5])))\n",
    "            mass_ls.append(abs(float(par[6])))  \n",
    "            charge_ls.append(int(par[0]))\n",
    "#             px_ls.append(6)\n",
    "#             py_ls.append(2)\n",
    "#             pz_ls.append(3)\n",
    "#             energy_ls.append(4)\n",
    "#             mass_ls.append(5)\n",
    "    if not n == 0:\n",
    "        n_particles_ls.append(n)\n",
    "    px_arr = np.array(px_ls)\n",
    "    py_arr = np.array(py_ls)\n",
    "    pz_arr = np.array(pz_ls)\n",
    "    energy_arr = np.array(energy_ls)\n",
    "    mass_arr = np.array(mass_ls)\n",
    "    charge_arr = np.array(charge_ls)\n",
    "    n_particles = np.array(n_particles_ls)\n",
    "\n",
    "#     print(n_particles)\n",
    "    px = ak.JaggedArray.fromcounts(n_particles, px_arr)\n",
    "    py = ak.JaggedArray.fromcounts(n_particles, py_arr)\n",
    "    pz = ak.JaggedArray.fromcounts(n_particles, pz_arr)\n",
    "    energy = ak.JaggedArray.fromcounts(n_particles, energy_arr)\n",
    "    mass = ak.JaggedArray.fromcounts(n_particles, mass_arr)\n",
    "    charge = ak.JaggedArray.fromcounts(n_particles, charge_arr)\n",
    "    p4 = uproot_methods.TLorentzVectorArray.from_cartesian(px, py, pz, energy)\n",
    "    ##Create an Order Dic\n",
    "    from collections import OrderedDict\n",
    "    v = OrderedDict()\n",
    "    v['part_px'] = px\n",
    "#     print(px)\n",
    "    v['part_py'] = py\n",
    "    v['part_pz'] = pz\n",
    "    v['part_energy'] = energy\n",
    "    v['part_mass'] = mass\n",
    "    v['charge'] = charge\n",
    "    v['part_e_log'] = np.log(energy)\n",
    "    v['part_px_log'] = np.log(px)\n",
    "    v['part_py_log'] = np.log(py)\n",
    "    v['part_pz_log'] = np.log(pz)\n",
    "    v['part_m_log'] = np.log(mass)\n",
    "#     ls1 = [1,2,3,4]\n",
    "#     ls2 = [5,6,7,8]\n",
    "#     v['label'] = np.stack((_label1, _label2, _label3, _label4, _label5), axis=-1)\n",
    "#     print(v['label'])\n",
    "    v['label'] = np.stack((_label4, _label5), axis = -1)\n",
    "#     v['label'] = np.stack(_label1, axis = -1)\n",
    "#     print(v['label'])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, filepath, feature_dict = {}, label = 'label', pad_len=100, data_format='channel_first'):\n",
    "        self.filepath = filepath\n",
    "        self.feature_dict = feature_dict\n",
    "        if len(feature_dict) == 0:\n",
    "            feature_dict['points'] = ['part_px','part_py','part_pz']\n",
    "            feature_dict['features'] = ['part_energy', 'part_mass', 'charge', 'part_px', 'part_py', 'part_pz']\n",
    "            feature_dict['mask'] = ['part_energy']\n",
    "        ##currently we use 'E' for experiments\n",
    "        self.label = label\n",
    "        self.pad_len = pad_len\n",
    "        assert data_format in ('channel_first', 'channel_last')\n",
    "        self.stack_axis = 1 if data_format=='channel_first' else -1\n",
    "        self._values = {}\n",
    "        self._label = None\n",
    "        self._load()\n",
    "        \n",
    "    def _load(self):\n",
    "        logging.info('Start loading file %s' % self.filepath)\n",
    "#         counts = None\n",
    "        a = SetAKArr(self.filepath)\n",
    "        self._label = a[self.label]\n",
    "        for k in self.feature_dict:\n",
    "                cols = self.feature_dict[k]\n",
    "                if not isinstance(cols, (list, tuple)):\n",
    "                    cols = [cols]\n",
    "                arrs = []\n",
    "                for col in cols:\n",
    "                    arrs.append(pad_array(a[col], self.pad_len))\n",
    "                    ##check the dimesion of a[col], and it should be array.\n",
    "                self._values[k] = np.stack(arrs, axis=self.stack_axis)\n",
    "        logging.info('Finished loading file %s' % self.filepath)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key==self.label:\n",
    "            return self._label\n",
    "        else:\n",
    "            return self._values[key]\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._values\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._label\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        shuffle_indices = np.arange(self.__len__())\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        for k in self._values:\n",
    "            self._values[k] = self._values[k][shuffle_indices]\n",
    "        self._label = self._label[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:02,927] INFO: Start loading file train.txt\n",
      "/home/htk/miniforge3/envs/tensorflow/lib/python3.5/site-packages/awkward/array/jagged.py:976: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "[2024-03-02 13:56:03,148] INFO: Finished loading file train.txt\n",
      "[2024-03-02 13:56:03,149] INFO: Start loading file val.txt\n",
      "[2024-03-02 13:56:03,181] INFO: Finished loading file val.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.28917911 5.27933   ]\n",
      " [5.28466195 5.27933   ]\n",
      " [5.2930648  5.27933   ]\n",
      " ...\n",
      " [5.29284146 5.27933   ]\n",
      " [5.30349918 5.27933   ]\n",
      " [5.28053101 5.27933   ]]\n",
      "[[5.29431961 5.27933   ]\n",
      " [5.28574823 5.27933   ]\n",
      " [5.29154575 5.27933   ]\n",
      " [5.30078546 5.27933   ]\n",
      " [5.29259698 5.27933   ]\n",
      " [5.28524332 5.27933   ]\n",
      " [5.29155483 5.27933   ]\n",
      " [5.27941453 5.27933   ]\n",
      " [5.29880525 5.27933   ]\n",
      " [5.29218013 5.27933   ]\n",
      " [5.29228723 5.27933   ]\n",
      " [5.28728002 5.27933   ]\n",
      " [5.28741552 5.27933   ]\n",
      " [5.2891755  5.27933   ]\n",
      " [5.28565425 5.27933   ]\n",
      " [5.29274715 5.27933   ]\n",
      " [5.2994644  5.27933   ]\n",
      " [5.30219958 5.27933   ]\n",
      " [5.3852338  5.27933   ]\n",
      " [5.28510522 5.27933   ]\n",
      " [5.29839353 5.27933   ]\n",
      " [5.28828447 5.27933   ]\n",
      " [5.29024063 5.27933   ]\n",
      " [5.28869517 5.27933   ]\n",
      " [5.2903763  5.27933   ]\n",
      " [5.31020409 5.27933   ]\n",
      " [5.29404419 5.27933   ]\n",
      " [5.28998162 5.27933   ]\n",
      " [5.29208506 5.27933   ]\n",
      " [5.28857468 5.27933   ]\n",
      " [5.28599418 5.27933   ]\n",
      " [5.28998564 5.27933   ]\n",
      " [5.30079814 5.27933   ]\n",
      " [5.29873706 5.27933   ]\n",
      " [5.28751108 5.27933   ]\n",
      " [5.28599689 5.27933   ]\n",
      " [5.28050096 5.27933   ]\n",
      " [5.3349217  5.27933   ]\n",
      " [5.33637289 5.27933   ]\n",
      " [5.29095021 5.27933   ]\n",
      " [5.29002055 5.27933   ]\n",
      " [5.28171171 5.27933   ]\n",
      " [5.28864088 5.27933   ]\n",
      " [5.2962566  5.27933   ]\n",
      " [5.2976727  5.27933   ]\n",
      " [5.30422273 5.27933   ]\n",
      " [5.27970596 5.27933   ]\n",
      " [5.29271524 5.27933   ]\n",
      " [5.30594616 5.27933   ]\n",
      " [5.28561793 5.27933   ]\n",
      " [5.29131474 5.27933   ]\n",
      " [5.28631845 5.27933   ]\n",
      " [5.30515503 5.27933   ]\n",
      " [5.29821642 5.27933   ]\n",
      " [5.31093298 5.27933   ]\n",
      " [5.28924391 5.27933   ]\n",
      " [5.28705531 5.27933   ]\n",
      " [5.28769743 5.27933   ]\n",
      " [5.29236493 5.27933   ]\n",
      " [5.28822381 5.27933   ]\n",
      " [5.28606301 5.27933   ]\n",
      " [5.2826982  5.27933   ]\n",
      " [5.28915071 5.27933   ]\n",
      " [5.27940331 5.27933   ]\n",
      " [5.29540756 5.27933   ]\n",
      " [5.28992887 5.27933   ]\n",
      " [5.31048835 5.27933   ]\n",
      " [5.32955102 5.27933   ]\n",
      " [5.31253874 5.27933   ]\n",
      " [5.29521442 5.27933   ]\n",
      " [5.30139709 5.27933   ]\n",
      " [5.28986858 5.27933   ]\n",
      " [5.28289768 5.27933   ]\n",
      " [5.29088238 5.27933   ]\n",
      " [5.28424279 5.27933   ]\n",
      " [5.28948221 5.27933   ]\n",
      " [5.36719501 5.27933   ]\n",
      " [5.28914168 5.27933   ]\n",
      " [5.30856945 5.27933   ]\n",
      " [5.29783515 5.27933   ]\n",
      " [5.29372105 5.27933   ]\n",
      " [5.30185468 5.27933   ]\n",
      " [5.2895831  5.27933   ]\n",
      " [5.2876964  5.27933   ]\n",
      " [5.29644206 5.27933   ]\n",
      " [5.29247524 5.27933   ]\n",
      " [5.27981425 5.27933   ]\n",
      " [5.30194984 5.27933   ]\n",
      " [5.28834286 5.27933   ]\n",
      " [5.28512849 5.27933   ]\n",
      " [5.32524014 5.27933   ]\n",
      " [5.28602398 5.27933   ]\n",
      " [5.29196781 5.27933   ]\n",
      " [5.28986277 5.27933   ]\n",
      " [5.28962236 5.27933   ]\n",
      " [5.28649859 5.27933   ]\n",
      " [5.28139081 5.27933   ]\n",
      " [5.33091079 5.27933   ]\n",
      " [5.28602465 5.27933   ]\n",
      " [5.28988599 5.27933   ]\n",
      " [5.29833675 5.27933   ]\n",
      " [5.28366009 5.27933   ]\n",
      " [5.28685621 5.27933   ]\n",
      " [5.2983539  5.27933   ]\n",
      " [5.29464921 5.27933   ]\n",
      " [5.28930497 5.27933   ]\n",
      " [5.2867062  5.27933   ]\n",
      " [5.29414713 5.27933   ]\n",
      " [5.30863457 5.27933   ]\n",
      " [5.30871985 5.27933   ]\n",
      " [5.28989983 5.27933   ]\n",
      " [5.33457273 5.27933   ]\n",
      " [5.28081811 5.27933   ]\n",
      " [5.29487742 5.27933   ]\n",
      " [5.29000802 5.27933   ]\n",
      " [5.29223762 5.27933   ]\n",
      " [5.2979798  5.27933   ]\n",
      " [5.2965317  5.27933   ]\n",
      " [5.28825708 5.27933   ]\n",
      " [5.30296263 5.27933   ]\n",
      " [5.28650417 5.27933   ]\n",
      " [5.28827967 5.27933   ]\n",
      " [5.28969059 5.27933   ]\n",
      " [5.29078882 5.27933   ]\n",
      " [5.30212559 5.27933   ]\n",
      " [5.30698369 5.27933   ]\n",
      " [5.28781829 5.27933   ]\n",
      " [5.29110488 5.27933   ]\n",
      " [5.28495422 5.27933   ]\n",
      " [5.28222705 5.27933   ]\n",
      " [5.28699004 5.27933   ]\n",
      " [5.29593948 5.27933   ]\n",
      " [5.29441176 5.27933   ]\n",
      " [5.28751003 5.27933   ]\n",
      " [5.28683108 5.27933   ]\n",
      " [5.29235248 5.27933   ]\n",
      " [5.29540057 5.27933   ]\n",
      " [5.30926086 5.27933   ]\n",
      " [5.30009353 5.27933   ]\n",
      " [5.29139352 5.27933   ]\n",
      " [5.2921357  5.27933   ]\n",
      " [5.3212809  5.27933   ]\n",
      " [5.29364594 5.27933   ]\n",
      " [5.28713722 5.27933   ]\n",
      " [5.3083321  5.27933   ]\n",
      " [5.29826865 5.27933   ]\n",
      " [5.2872302  5.27933   ]\n",
      " [5.29038583 5.27933   ]\n",
      " [5.2952395  5.27933   ]\n",
      " [5.2922454  5.27933   ]\n",
      " [5.28400421 5.27933   ]\n",
      " [5.28979673 5.27933   ]\n",
      " [5.2840676  5.27933   ]\n",
      " [5.29341248 5.27933   ]\n",
      " [5.28572399 5.27933   ]\n",
      " [5.28852738 5.27933   ]\n",
      " [5.27963705 5.27933   ]\n",
      " [5.28322367 5.27933   ]\n",
      " [5.2910475  5.27933   ]\n",
      " [5.32045114 5.27933   ]\n",
      " [5.292968   5.27933   ]\n",
      " [5.28748996 5.27933   ]\n",
      " [5.28319231 5.27933   ]\n",
      " [5.30747631 5.27933   ]\n",
      " [5.30625696 5.27933   ]\n",
      " [5.29118044 5.27933   ]\n",
      " [5.31144668 5.27933   ]\n",
      " [5.33520476 5.27933   ]\n",
      " [5.28347024 5.27933   ]\n",
      " [5.32175702 5.27933   ]\n",
      " [5.29327287 5.27933   ]\n",
      " [5.2963527  5.27933   ]\n",
      " [5.28635863 5.27933   ]\n",
      " [5.2913118  5.27933   ]\n",
      " [5.29618884 5.27933   ]\n",
      " [5.28783093 5.27933   ]\n",
      " [5.28611705 5.27933   ]\n",
      " [5.28943618 5.27933   ]\n",
      " [5.28497571 5.27933   ]\n",
      " [5.36185379 5.27933   ]\n",
      " [5.29143467 5.27933   ]\n",
      " [5.29955801 5.27933   ]\n",
      " [5.28279197 5.27933   ]\n",
      " [5.28608041 5.27933   ]\n",
      " [5.29132995 5.27933   ]\n",
      " [5.39461783 5.27933   ]\n",
      " [5.2963984  5.27933   ]\n",
      " [5.29158261 5.27933   ]\n",
      " [5.30450955 5.27933   ]\n",
      " [5.29986508 5.27933   ]\n",
      " [5.29096156 5.27933   ]\n",
      " [5.28416996 5.27933   ]\n",
      " [5.29037903 5.27933   ]\n",
      " [5.28736025 5.27933   ]\n",
      " [5.28200082 5.27933   ]\n",
      " [5.28503884 5.27933   ]\n",
      " [5.33791909 5.27933   ]\n",
      " [5.28386377 5.27933   ]\n",
      " [5.28895315 5.27933   ]\n",
      " [5.29442907 5.27933   ]\n",
      " [5.28446713 5.27933   ]\n",
      " [5.29196888 5.27933   ]\n",
      " [5.29604006 5.27933   ]\n",
      " [5.2871617  5.27933   ]\n",
      " [5.29539758 5.27933   ]\n",
      " [5.30507439 5.27933   ]\n",
      " [5.32586361 5.27933   ]\n",
      " [5.29166708 5.27933   ]\n",
      " [5.29844563 5.27933   ]\n",
      " [5.39013417 5.27933   ]\n",
      " [5.28719494 5.27933   ]\n",
      " [5.28611904 5.27933   ]\n",
      " [5.28981235 5.27933   ]\n",
      " [5.28410781 5.27933   ]\n",
      " [5.28960273 5.27933   ]\n",
      " [5.28707279 5.27933   ]\n",
      " [5.29066866 5.27933   ]\n",
      " [5.28633251 5.27933   ]\n",
      " [5.2898784  5.27933   ]\n",
      " [5.28491514 5.27933   ]\n",
      " [5.29145558 5.27933   ]\n",
      " [5.29863171 5.27933   ]\n",
      " [5.298198   5.27933   ]\n",
      " [5.30080829 5.27933   ]\n",
      " [5.29351059 5.27933   ]\n",
      " [5.30556995 5.27933   ]\n",
      " [5.29204881 5.27933   ]\n",
      " [5.29370666 5.27933   ]\n",
      " [5.29507489 5.27933   ]\n",
      " [5.28675564 5.27933   ]\n",
      " [5.28999146 5.27933   ]\n",
      " [5.29317696 5.27933   ]\n",
      " [5.28737747 5.27933   ]\n",
      " [5.28899636 5.27933   ]\n",
      " [5.279875   5.27933   ]\n",
      " [5.29620046 5.27933   ]\n",
      " [5.29140392 5.27933   ]\n",
      " [5.28448532 5.27933   ]\n",
      " [5.31901766 5.27933   ]\n",
      " [5.29074926 5.27933   ]\n",
      " [5.29047091 5.27933   ]\n",
      " [5.29553909 5.27933   ]\n",
      " [5.28135021 5.27933   ]\n",
      " [5.29237287 5.27933   ]\n",
      " [5.29450224 5.27933   ]\n",
      " [5.29049738 5.27933   ]\n",
      " [5.31586532 5.27933   ]\n",
      " [5.29714763 5.27933   ]\n",
      " [5.29713515 5.27933   ]\n",
      " [5.29325104 5.27933   ]\n",
      " [5.29250414 5.27933   ]\n",
      " [5.29101086 5.27933   ]\n",
      " [5.2907052  5.27933   ]\n",
      " [5.29092567 5.27933   ]\n",
      " [5.28504047 5.27933   ]\n",
      " [5.2859833  5.27933   ]\n",
      " [5.28898318 5.27933   ]\n",
      " [5.29085986 5.27933   ]\n",
      " [5.28236607 5.27933   ]\n",
      " [5.29193324 5.27933   ]\n",
      " [5.29536676 5.27933   ]\n",
      " [5.32579579 5.27933   ]\n",
      " [5.28829598 5.27933   ]\n",
      " [5.40097485 5.27933   ]\n",
      " [5.31885313 5.27933   ]\n",
      " [5.28976194 5.27933   ]\n",
      " [5.2935523  5.27933   ]\n",
      " [5.28717336 5.27933   ]\n",
      " [5.30017844 5.27933   ]\n",
      " [5.29520193 5.27933   ]\n",
      " [5.29073069 5.27933   ]\n",
      " [5.29837626 5.27933   ]\n",
      " [5.2854075  5.27933   ]\n",
      " [5.29285129 5.27933   ]\n",
      " [5.29185147 5.27933   ]\n",
      " [5.28744965 5.27933   ]\n",
      " [5.33064892 5.27933   ]\n",
      " [5.29104083 5.27933   ]\n",
      " [5.29493177 5.27933   ]\n",
      " [5.30545735 5.27933   ]\n",
      " [5.29284392 5.27933   ]\n",
      " [5.29197528 5.27933   ]\n",
      " [5.28600503 5.27933   ]\n",
      " [5.29334021 5.27933   ]\n",
      " [5.29307566 5.27933   ]\n",
      " [5.29013399 5.27933   ]\n",
      " [5.27966514 5.27933   ]\n",
      " [5.29314062 5.27933   ]\n",
      " [5.28709472 5.27933   ]\n",
      " [5.28182225 5.27933   ]\n",
      " [5.28702021 5.27933   ]\n",
      " [5.30590193 5.27933   ]\n",
      " [5.29075623 5.27933   ]\n",
      " [5.3052683  5.27933   ]\n",
      " [5.29275439 5.27933   ]\n",
      " [5.28927041 5.27933   ]\n",
      " [5.2983009  5.27933   ]\n",
      " [5.28484201 5.27933   ]\n",
      " [5.29081775 5.27933   ]\n",
      " [5.28808124 5.27933   ]\n",
      " [5.29322733 5.27933   ]\n",
      " [5.29407879 5.27933   ]\n",
      " [5.28689284 5.27933   ]\n",
      " [5.28926502 5.27933   ]\n",
      " [5.30198285 5.27933   ]\n",
      " [5.29593063 5.27933   ]\n",
      " [5.28736132 5.27933   ]\n",
      " [5.2931724  5.27933   ]\n",
      " [5.29070798 5.27933   ]\n",
      " [5.2872335  5.27933   ]\n",
      " [5.29346303 5.27933   ]\n",
      " [5.30684132 5.27933   ]\n",
      " [5.28758817 5.27933   ]\n",
      " [5.2908946  5.27933   ]\n",
      " [5.40743829 5.27933   ]\n",
      " [5.27946144 5.27933   ]\n",
      " [5.29093699 5.27933   ]\n",
      " [5.29680478 5.27933   ]\n",
      " [5.28414189 5.27933   ]\n",
      " [5.30556995 5.27933   ]\n",
      " [5.28913582 5.27933   ]\n",
      " [5.29013354 5.27933   ]\n",
      " [5.30392232 5.27933   ]\n",
      " [5.28897227 5.27933   ]\n",
      " [5.28832757 5.27933   ]\n",
      " [5.28620595 5.27933   ]\n",
      " [5.28190413 5.27933   ]\n",
      " [5.2847532  5.27933   ]\n",
      " [5.2887953  5.27933   ]\n",
      " [5.28972805 5.27933   ]\n",
      " [5.27938757 5.27933   ]\n",
      " [5.28455652 5.27933   ]\n",
      " [5.29892695 5.27933   ]\n",
      " [5.28958845 5.27933   ]\n",
      " [5.33450357 5.27933   ]\n",
      " [5.30017382 5.27933   ]\n",
      " [5.29000041 5.27933   ]\n",
      " [5.2824242  5.27933   ]\n",
      " [5.2886873  5.27933   ]\n",
      " [5.28457172 5.27933   ]\n",
      " [5.29152714 5.27933   ]\n",
      " [5.28097316 5.27933   ]\n",
      " [5.30719008 5.27933   ]\n",
      " [5.29396736 5.27933   ]\n",
      " [5.28792187 5.27933   ]\n",
      " [5.28226041 5.27933   ]\n",
      " [5.28598534 5.27933   ]\n",
      " [5.30266316 5.27933   ]\n",
      " [5.29070751 5.27933   ]\n",
      " [5.29033144 5.27933   ]\n",
      " [5.28612832 5.27933   ]\n",
      " [5.28634463 5.27933   ]\n",
      " [5.42321058 5.27933   ]\n",
      " [5.29066404 5.27933   ]\n",
      " [5.29227214 5.27933   ]\n",
      " [5.29853883 5.27933   ]\n",
      " [5.29739453 5.27933   ]\n",
      " [5.28230319 5.27933   ]\n",
      " [5.28821657 5.27933   ]\n",
      " [5.29932153 5.27933   ]\n",
      " [5.28584755 5.27933   ]\n",
      " [5.29896109 5.27933   ]\n",
      " [5.30038496 5.27933   ]\n",
      " [5.288995   5.27933   ]\n",
      " [5.28925694 5.27933   ]\n",
      " [5.35091513 5.27933   ]\n",
      " [5.29110631 5.27933   ]\n",
      " [5.31533284 5.27933   ]\n",
      " [5.28787678 5.27933   ]\n",
      " [5.31376073 5.27933   ]\n",
      " [5.28401018 5.27933   ]\n",
      " [5.2859478  5.27933   ]\n",
      " [5.29223207 5.27933   ]\n",
      " [5.28511165 5.27933   ]\n",
      " [5.28815791 5.27933   ]\n",
      " [5.28425894 5.27933   ]\n",
      " [5.28493929 5.27933   ]\n",
      " [5.29063176 5.27933   ]\n",
      " [5.29314903 5.27933   ]\n",
      " [5.28988197 5.27933   ]\n",
      " [5.29727395 5.27933   ]\n",
      " [5.30112826 5.27933   ]\n",
      " [5.30358797 5.27933   ]\n",
      " [5.287584   5.27933   ]\n",
      " [5.28292838 5.27933   ]\n",
      " [5.28741285 5.27933   ]\n",
      " [5.29064328 5.27933   ]\n",
      " [5.28962102 5.27933   ]\n",
      " [5.29186775 5.27933   ]\n",
      " [5.32222893 5.27933   ]\n",
      " [5.28554527 5.27933   ]\n",
      " [5.29369446 5.27933   ]\n",
      " [5.29661028 5.27933   ]\n",
      " [5.28260407 5.27933   ]\n",
      " [5.28432959 5.27933   ]\n",
      " [5.28852644 5.27933   ]\n",
      " [5.28894404 5.27933   ]\n",
      " [5.29804456 5.27933   ]\n",
      " [5.29231359 5.27933   ]\n",
      " [5.29818464 5.27933   ]\n",
      " [5.30373821 5.27933   ]\n",
      " [5.29768033 5.27933   ]\n",
      " [5.2862599  5.27933   ]\n",
      " [5.29257056 5.27933   ]\n",
      " [5.28865529 5.27933   ]\n",
      " [5.28316077 5.27933   ]\n",
      " [5.29052252 5.27933   ]\n",
      " [5.29001025 5.27933   ]\n",
      " [5.28039844 5.27933   ]\n",
      " [5.29254776 5.27933   ]\n",
      " [5.29032012 5.27933   ]\n",
      " [5.2925262  5.27933   ]\n",
      " [5.29682959 5.27933   ]\n",
      " [5.2946217  5.27933   ]\n",
      " [5.2900107  5.27933   ]\n",
      " [5.29139649 5.27933   ]\n",
      " [5.29221379 5.27933   ]\n",
      " [5.31164328 5.27933   ]\n",
      " [5.28521583 5.27933   ]\n",
      " [5.29702821 5.27933   ]\n",
      " [5.29304887 5.27933   ]\n",
      " [5.2924167  5.27933   ]\n",
      " [5.28957641 5.27933   ]\n",
      " [5.29436588 5.27933   ]\n",
      " [5.29025642 5.27933   ]\n",
      " [5.30518208 5.27933   ]\n",
      " [5.28387502 5.27933   ]\n",
      " [5.28968568 5.27933   ]\n",
      " [5.28148549 5.27933   ]\n",
      " [5.29112936 5.27933   ]\n",
      " [5.28527844 5.27933   ]\n",
      " [5.29270265 5.27933   ]\n",
      " [5.28489926 5.27933   ]\n",
      " [5.28839142 5.27933   ]\n",
      " [5.2860233  5.27933   ]\n",
      " [5.28897272 5.27933   ]\n",
      " [5.31484316 5.27933   ]\n",
      " [5.36995186 5.27933   ]\n",
      " [5.29561341 5.27933   ]\n",
      " [5.28524097 5.27933   ]\n",
      " [5.29614491 5.27933   ]\n",
      " [5.28313727 5.27933   ]\n",
      " [5.2802019  5.27933   ]\n",
      " [5.32086911 5.27933   ]\n",
      " [5.3038259  5.27933   ]\n",
      " [5.29084674 5.27933   ]\n",
      " [5.29128342 5.27933   ]\n",
      " [5.28914168 5.27933   ]\n",
      " [5.29347471 5.27933   ]\n",
      " [5.28106803 5.27933   ]\n",
      " [5.29002682 5.27933   ]\n",
      " [5.33165581 5.27933   ]\n",
      " [5.29371889 5.27933   ]\n",
      " [5.2821371  5.27933   ]\n",
      " [5.29847186 5.27933   ]\n",
      " [5.28514927 5.27933   ]\n",
      " [5.28297107 5.27933   ]\n",
      " [5.30497685 5.27933   ]\n",
      " [5.30287731 5.27933   ]\n",
      " [5.28904401 5.27933   ]\n",
      " [5.39770309 5.27933   ]\n",
      " [5.28887739 5.27933   ]\n",
      " [5.28777872 5.27933   ]\n",
      " [5.29149703 5.27933   ]\n",
      " [5.30050284 5.27933   ]\n",
      " [5.36951508 5.27933   ]\n",
      " [5.28981458 5.27933   ]\n",
      " [5.29472211 5.27933   ]\n",
      " [5.29777582 5.27933   ]\n",
      " [5.28652765 5.27933   ]\n",
      " [5.28832566 5.27933   ]\n",
      " [5.30030204 5.27933   ]\n",
      " [5.29082288 5.27933   ]\n",
      " [5.2848174  5.27933   ]]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset('train.txt', data_format='channel_last')\n",
    "val_dataset = Dataset('val.txt', data_format='channel_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tf_keras_model import get_particle_net, get_particle_net_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'particle_net_lite' # choose between 'particle_net' and 'particle_net_lite'\n",
    "##this shows the number of classes for classification\n",
    "num_classes = train_dataset.y.shape[1]\n",
    "# num_classes = 1\n",
    "# print(num_classes)\n",
    "input_shapes = {k:train_dataset[k].shape[1:] for k in train_dataset.X}\n",
    "if 'lite' in model_type:\n",
    "    model = get_particle_net_lite(num_classes, input_shapes)\n",
    "else:\n",
    "    model = get_particle_net(num_classes, input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 1024 if 'lite' in model_type else 384\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 10:\n",
    "        lr *= 0.1\n",
    "    elif epoch > 20:\n",
    "        lr *= 0.01\n",
    "    logging.info('Learning rate: %f'%lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:16,808] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ParticleNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mask (InputLayer)               [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_NotEqual (TensorFlo [(None, 100, 1)]     0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast (TensorFlowOpL [(None, 100, 1)]     0           tf_op_layer_NotEqual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_1 (TensorFlowO [(None, 100, 1)]     0           tf_op_layer_Equal[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 100, 1)]     0           tf_op_layer_Cast_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "points (InputLayer)             [(None, 100, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add (TensorFlowOpLa [(None, 100, 3)]     0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 100, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose (TensorFl [(None, 3, 100)]     0           tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 100, 1, 6)]  0           features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 100, 3)]     0           tf_op_layer_Add[0][0]            \n",
      "                                                                 tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2 (Tens [(None, 100, 100)]   0           tf_op_layer_Add[0][0]            \n",
      "                                                                 tf_op_layer_Transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_2 (TensorFlowOp [(None, 100, 3)]     0           tf_op_layer_Add[0][0]            \n",
      "                                                                 tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_fts_bn (BatchNormal (None, 100, 1, 6)    24          tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None, 100, 1)]     0           tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_3 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_BatchMatMulV2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 100, 6)]     0           ParticleNet_fts_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 100, 100)]   0           tf_op_layer_Sum[0][0]            \n",
      "                                                                 tf_op_layer_Mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_1 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(3,)]               0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 tf_op_layer_Transpose_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg (TensorFlowOpLa [(None, 100, 100)]   0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range (TensorFlowOp [(None,)]            0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2 (TensorFlowO [(None, 100, 8), (No 0           tf_op_layer_Neg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 1, 1, 1)]    0           tf_op_layer_Range[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 100, 7)]     0           tf_op_layer_TopKV2[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile (TensorFlowOpL [(None, 100, 7, 1)]  0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(None, 100, 1, 6)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 100, 7, 2)]  0           tf_op_layer_Tile[0][0]           \n",
      "                                                                 tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_1 (TensorFlowO [(None, 100, 7, 6)]  0           tf_op_layer_ExpandDims_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd (TensorFlo [(None, 100, 7, 6)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "                                                                 tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 100, 7, 6)]  0           tf_op_layer_GatherNd[0][0]       \n",
      "                                                                 tf_op_layer_Tile_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 100, 7, 12)] 0           tf_op_layer_Tile_1[0][0]         \n",
      "                                                                 tf_op_layer_Sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv0 (Co (None, 100, 7, 32)   384         tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn0 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act0 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv1 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn1 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act1 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_3 (Tenso [(None, 100, 1, 6)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv2 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_conv ( (None, 100, 1, 32)   192         tf_op_layer_ExpandDims_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn2 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_bn (Ba (None, 100, 1, 32)   128         ParticleNet_EdgeConv0_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act2 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_1 (TensorFl [(None, 100, 32)]    0           ParticleNet_EdgeConv0_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 100, 32)]    0           ParticleNet_EdgeConv0_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 100, 32)]    0           tf_op_layer_Squeeze_1[0][0]      \n",
      "                                                                 tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_act (A (None, 100, 32)      0           tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_1 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_2 (Tensor [(None, 32, 100)]    0           tf_op_layer_Add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_4 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Add_1[0][0]          \n",
      "                                                                 tf_op_layer_Add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_1 (Te [(None, 100, 100)]   0           tf_op_layer_Add_1[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_5 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Add_1[0][0]          \n",
      "                                                                 tf_op_layer_Add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_2 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_6 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_BatchMatMulV2_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_3 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sum_2[0][0]          \n",
      "                                                                 tf_op_layer_Mul_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_3 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(3,)]               0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 100, 100)]   0           tf_op_layer_Sub_2[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_1 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_1 (TensorFlow [(None,)]            0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2_1 (TensorFlo [(None, 100, 8), (No 0           tf_op_layer_Neg_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 1, 1, 1)]    0           tf_op_layer_Range_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 100, 7)]     0           tf_op_layer_TopKV2_1[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_2 (TensorFlowO [(None, 100, 7, 1)]  0           tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_4 (Tenso [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_5 (Tenso [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_2 (TensorFlo [(None, 100, 7, 2)]  0           tf_op_layer_Tile_2[0][0]         \n",
      "                                                                 tf_op_layer_ExpandDims_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_3 (TensorFlowO [(None, 100, 7, 32)] 0           tf_op_layer_ExpandDims_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_1 (TensorF [(None, 100, 7, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "                                                                 tf_op_layer_concat_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_3 (TensorFlowOp [(None, 100, 7, 32)] 0           tf_op_layer_GatherNd_1[0][0]     \n",
      "                                                                 tf_op_layer_Tile_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 100, 7, 64)] 0           tf_op_layer_Tile_3[0][0]         \n",
      "                                                                 tf_op_layer_Sub_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv0 (Co (None, 100, 7, 64)   4096        tf_op_layer_concat_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn0 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act0 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv1 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn1 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act1 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_6 (Tenso [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv2 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_conv ( (None, 100, 1, 64)   2048        tf_op_layer_ExpandDims_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn2 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_bn (Ba (None, 100, 1, 64)   256         ParticleNet_EdgeConv1_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act2 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_2 (TensorFl [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [(None, 100, 64)]    0           ParticleNet_EdgeConv1_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 100, 64)]    0           tf_op_layer_Squeeze_2[0][0]      \n",
      "                                                                 tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_act (A (None, 100, 64)      0           tf_op_layer_AddV2_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_7 (TensorFlowOp [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_act[0][0\n",
      "                                                                 tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_2 (TensorFlowO [(None, 64)]         0           tf_op_layer_Mul_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          8320        tf_op_layer_Mean_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 27,098\n",
      "Trainable params: 26,318\n",
      "Non-trainable params: 780\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "#               metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "import os\n",
    "save_dir = 'model_checkpoints'\n",
    "model_name = '%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "progress_bar = keras.callbacks.ProgbarLogger()\n",
    "callbacks = [checkpoint, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:19,094] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.7631 - loss: 28.3624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:25,574] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 837ms/step - accuracy: 0.7631 - loss: 28.3624 - val_accuracy: 0.5190 - val_loss: 27.4525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:25,578] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.9864 - loss: 22.7647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:30,759] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 793ms/step - accuracy: 0.9864 - loss: 22.7647 - val_accuracy: 1.0000 - val_loss: 26.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:30,762] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.9916 - loss: 17.4207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:35,709] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 750ms/step - accuracy: 0.9916 - loss: 17.4207 - val_accuracy: 1.0000 - val_loss: 26.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:35,711] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.9779 - loss: 11.7340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:40,695] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 783ms/step - accuracy: 0.9779 - loss: 11.7340 - val_accuracy: 1.0000 - val_loss: 24.9532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:40,699] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.9411 - loss: 6.2564"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:46,190] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 845ms/step - accuracy: 0.9411 - loss: 6.2564 - val_accuracy: 0.9747 - val_loss: 23.5695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:46,192] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.8336 - loss: 2.1521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:51,613] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 846ms/step - accuracy: 0.8336 - loss: 2.1521 - val_accuracy: 0.3882 - val_loss: 21.9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:51,615] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.6698 - loss: 0.5303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:56,855] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 811ms/step - accuracy: 0.6698 - loss: 0.5303 - val_accuracy: 0.0000e+00 - val_loss: 20.5835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:56:56,860] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.4816 - loss: 0.8900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:02,145] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 799ms/step - accuracy: 0.4816 - loss: 0.8900 - val_accuracy: 0.0000e+00 - val_loss: 19.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:02,149] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.3856 - loss: 0.7937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:07,447] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 827ms/step - accuracy: 0.3856 - loss: 0.7937 - val_accuracy: 0.0000e+00 - val_loss: 19.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:07,451] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.3795 - loss: 0.3247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:12,688] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 805ms/step - accuracy: 0.3795 - loss: 0.3247 - val_accuracy: 0.0000e+00 - val_loss: 20.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:12,690] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.4200 - loss: 0.2466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:17,871] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 803ms/step - accuracy: 0.4200 - loss: 0.2466 - val_accuracy: 0.0000e+00 - val_loss: 20.1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:17,874] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.4854 - loss: 0.2762"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:23,116] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 804ms/step - accuracy: 0.4854 - loss: 0.2762 - val_accuracy: 0.0000e+00 - val_loss: 20.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:23,118] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.5052 - loss: 0.2795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:28,376] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 805ms/step - accuracy: 0.5052 - loss: 0.2795 - val_accuracy: 0.0000e+00 - val_loss: 20.0654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:28,378] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.5043 - loss: 0.2606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:33,616] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 814ms/step - accuracy: 0.5043 - loss: 0.2606 - val_accuracy: 0.0000e+00 - val_loss: 19.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:33,618] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.5061 - loss: 0.2457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-02 13:57:38,909] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5/5 [==============================] - 4s 813ms/step - accuracy: 0.5061 - loss: 0.2457 - val_accuracy: 0.0000e+00 - val_loss: 19.8490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f541f4585c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shuffle()\n",
    "model.fit(train_dataset.X, train_dataset.y,\n",
    "          batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "          epochs=15, # --- train only for 1 epoch here for demonstration ---\n",
    "          validation_data=(val_dataset.X, val_dataset.y),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81566733 0.8419997 ]\n",
      "[0.7763244 0.8333638]\n",
      "[0.8814611  0.94231457]\n",
      "[0.8059118  0.84061307]\n",
      "[0.800409  0.8586278]\n",
      "[0.794723  0.8513902]\n",
      "[0.8450996 0.8829296]\n",
      "[0.7606166  0.78812855]\n",
      "[0.83673567 0.8708411 ]\n",
      "[0.797791   0.83190423]\n",
      "[0.8492246  0.87396985]\n",
      "[0.76914084 0.81507653]\n",
      "[0.7250046 0.7833844]\n",
      "[0.8454234  0.89155895]\n",
      "[0.8084389  0.84663886]\n",
      "[0.76829237 0.79752666]\n",
      "[0.8014586 0.8500824]\n",
      "[0.82727224 0.85501397]\n",
      "[0.84449154 0.893961  ]\n",
      "[0.87033206 0.91251904]\n",
      "[0.78092766 0.83082753]\n",
      "[0.8494279  0.88037974]\n",
      "[0.7671171  0.83008164]\n",
      "[0.83558804 0.8672809 ]\n",
      "[0.7874028  0.82682735]\n",
      "[0.8468027 0.8712953]\n",
      "[0.82483774 0.8575669 ]\n",
      "[0.8609012  0.88719565]\n",
      "[0.8809435 0.9194246]\n",
      "[0.81847644 0.8526326 ]\n",
      "[0.84798557 0.88274235]\n",
      "[0.73060113 0.7845528 ]\n",
      "[0.8040942 0.8346309]\n",
      "[0.78252846 0.8210624 ]\n",
      "[0.81995493 0.8528581 ]\n",
      "[0.80983704 0.8465799 ]\n",
      "[0.87252754 0.9165501 ]\n",
      "[0.85170454 0.89759773]\n",
      "[0.72482663 0.76189774]\n",
      "[0.7590944 0.8161345]\n",
      "[0.896444   0.94038475]\n",
      "[0.7336928 0.7760537]\n",
      "[0.7311706 0.7910215]\n",
      "[0.8214863 0.8561812]\n",
      "[0.773504   0.82265395]\n",
      "[0.8115025 0.873975 ]\n",
      "[0.92696637 0.9615781 ]\n",
      "[0.8387488 0.893905 ]\n",
      "[0.8978871 0.9358624]\n",
      "[0.8687155 0.9063186]\n",
      "[0.7617294 0.8052746]\n",
      "[0.85032004 0.884198  ]\n",
      "[0.76747614 0.7995042 ]\n",
      "[0.8340774 0.8705068]\n",
      "[0.8368289 0.8730127]\n",
      "[0.84163314 0.8788883 ]\n",
      "[0.7895176  0.84256744]\n",
      "[0.7950247 0.8334463]\n",
      "[0.7594686 0.7937079]\n",
      "[0.8423379 0.8989329]\n",
      "[0.7426875  0.78613895]\n",
      "[0.84304035 0.88554585]\n",
      "[0.81348485 0.8591511 ]\n",
      "[0.7726004  0.81831634]\n",
      "[0.7854515 0.8209459]\n",
      "[0.72672594 0.7884715 ]\n",
      "[0.705113   0.76833355]\n",
      "[0.7409091 0.78674  ]\n",
      "[0.87584597 0.9212204 ]\n",
      "[0.875608   0.91022784]\n",
      "[0.86719364 0.9115582 ]\n",
      "[0.8318085 0.8697687]\n",
      "[0.82957166 0.86468333]\n",
      "[0.8731509 0.9059944]\n",
      "[0.8616208 0.9195289]\n",
      "[0.8413882  0.86138934]\n",
      "[0.8002266 0.8265751]\n",
      "[0.8511754  0.90403503]\n",
      "[0.84233505 0.87412673]\n",
      "[0.7860646  0.82519776]\n",
      "[0.78318113 0.8278244 ]\n",
      "[0.803061   0.83145833]\n",
      "[0.8739756 0.9248418]\n",
      "[0.8285276 0.8797769]\n",
      "[0.80681795 0.8494324 ]\n",
      "[0.82554907 0.8648258 ]\n",
      "[0.84711474 0.9097621 ]\n",
      "[0.85995287 0.89800054]\n",
      "[0.6724109 0.7269463]\n",
      "[0.8084696 0.8559746]\n",
      "[0.7297599  0.78243536]\n",
      "[0.8406706  0.87956023]\n",
      "[0.7477817 0.8088166]\n",
      "[0.8155692 0.8661822]\n",
      "[0.8403726 0.8703031]\n",
      "[0.8523558 0.8845272]\n",
      "[0.80127805 0.84578025]\n",
      "[0.79845923 0.83888704]\n",
      "[0.7866382 0.8183613]\n",
      "[0.7781815 0.8202446]\n",
      "[0.84499234 0.8769124 ]\n",
      "[0.7997434  0.85744363]\n",
      "[0.8584189 0.9101525]\n",
      "[0.77794695 0.823633  ]\n",
      "[0.8733562  0.88934946]\n",
      "[0.76899606 0.82184213]\n",
      "[0.8295612  0.86937183]\n",
      "[0.78238267 0.8251956 ]\n",
      "[0.79987377 0.8469179 ]\n",
      "[0.88049394 0.92284256]\n",
      "[0.85990685 0.902554  ]\n",
      "[0.73426247 0.80975217]\n",
      "[0.7667184 0.8088196]\n",
      "[0.8328619  0.85845286]\n",
      "[0.81885093 0.86633354]\n",
      "[0.74958104 0.78614944]\n",
      "[0.7436436 0.8063677]\n",
      "[0.85186064 0.8914083 ]\n",
      "[0.83311623 0.86471206]\n",
      "[0.8215633  0.85540974]\n",
      "[0.8116761 0.8659607]\n",
      "[0.8940812  0.92326045]\n",
      "[0.7802693 0.836127 ]\n",
      "[0.8297586 0.8718241]\n",
      "[0.8762224  0.92237145]\n",
      "[0.771913  0.8316068]\n",
      "[0.7757469 0.8218226]\n",
      "[0.8397471 0.8733648]\n",
      "[0.8754569 0.9085857]\n",
      "[0.80579495 0.8575744 ]\n",
      "[0.7995984  0.82937557]\n",
      "[0.8344154  0.87747437]\n",
      "[0.7826974  0.82818335]\n",
      "[0.7802077 0.8149373]\n",
      "[0.75226325 0.7949104 ]\n",
      "[0.82831246 0.86483794]\n",
      "[0.85071695 0.8729177 ]\n",
      "[0.7657316  0.79353654]\n",
      "[0.77303094 0.81146497]\n",
      "[0.8758438  0.91333723]\n",
      "[0.7465319  0.79951155]\n",
      "[0.8813721  0.93035525]\n",
      "[0.80868894 0.86193275]\n",
      "[0.83130074 0.88469803]\n",
      "[0.81925756 0.8542158 ]\n",
      "[0.84637296 0.87077516]\n",
      "[0.89464945 0.93370134]\n",
      "[0.74124885 0.7954846 ]\n",
      "[0.82391787 0.84717315]\n",
      "[0.7717207 0.8095067]\n",
      "[0.8610058 0.8956705]\n",
      "[0.7943849  0.83777803]\n",
      "[0.6871523 0.7334618]\n",
      "[0.8495541  0.87850213]\n",
      "[0.7375625 0.7779184]\n",
      "[0.80446094 0.8464417 ]\n",
      "[0.7136353 0.7485339]\n",
      "[0.7638201  0.81934446]\n",
      "[0.8255952 0.8616703]\n",
      "[0.84995013 0.89479697]\n",
      "[0.8017359 0.8441395]\n",
      "[0.8142225 0.860756 ]\n",
      "[0.778897   0.82746035]\n",
      "[0.7576112 0.8076449]\n",
      "[0.8226654  0.85748655]\n",
      "[0.76504695 0.81411266]\n",
      "[0.8160501 0.8527638]\n",
      "[0.71348274 0.7552288 ]\n",
      "[0.8634209 0.9050341]\n",
      "[0.7449368  0.80674714]\n",
      "[0.75085765 0.79649156]\n",
      "[0.8005714 0.8345565]\n",
      "[0.8460894  0.86274296]\n",
      "[0.76550335 0.8078204 ]\n",
      "[0.81644106 0.84112054]\n",
      "[0.85838777 0.8882447 ]\n",
      "[0.83371663 0.85992485]\n",
      "[0.88536006 0.9259294 ]\n",
      "[0.8289519 0.8640402]\n",
      "[0.88920987 0.919866  ]\n",
      "[0.79172415 0.8406947 ]\n",
      "[0.76156145 0.80575   ]\n",
      "[0.81779295 0.8476905 ]\n",
      "[0.861656  0.8872278]\n",
      "[0.78179747 0.82433647]\n",
      "[0.8960847 0.9588371]\n",
      "[0.7441581  0.78288895]\n",
      "[0.77132946 0.8212927 ]\n",
      "[0.61675614 0.6647369 ]\n",
      "[0.7600641 0.8179994]\n",
      "[0.7725522  0.81200844]\n",
      "[0.6984365 0.7506896]\n",
      "[0.82487506 0.86810106]\n",
      "[0.72421056 0.7658523 ]\n",
      "[0.85854787 0.8846056 ]\n",
      "[0.87726957 0.9184925 ]\n",
      "[0.8468433  0.87130123]\n",
      "[0.8568221 0.899455 ]\n",
      "[0.7350002  0.79139155]\n",
      "[0.7745966  0.82063085]\n",
      "[0.7950461 0.8213635]\n",
      "[0.8695478  0.90618366]\n",
      "[0.849057  0.8958059]\n",
      "[0.7254398 0.7774627]\n",
      "[0.73166996 0.776287  ]\n",
      "[0.7927863  0.81926244]\n",
      "[0.8783135  0.92243916]\n",
      "[0.8695952  0.91302294]\n",
      "[0.80685633 0.851306  ]\n",
      "[0.8388477  0.86865836]\n",
      "[0.7500628  0.78420186]\n",
      "[0.8273238  0.88439614]\n",
      "[0.7663601 0.8168142]\n",
      "[0.82596534 0.86591   ]\n",
      "[0.81381696 0.8485015 ]\n",
      "[0.80008936 0.83970124]\n",
      "[0.85668    0.88807553]\n",
      "[0.8526527  0.88061625]\n",
      "[0.8317794 0.8657692]\n",
      "[0.8653638 0.9069625]\n",
      "[0.8566615 0.8903602]\n",
      "[0.8237317 0.8698599]\n",
      "[0.82120174 0.856363  ]\n",
      "[0.8401397 0.8813719]\n",
      "[0.7723661 0.8148043]\n",
      "[0.84357566 0.8733093 ]\n",
      "[0.80468553 0.84948397]\n",
      "[0.7661948 0.7978744]\n",
      "[0.8358314  0.87782127]\n",
      "[0.91492337 0.9565844 ]\n",
      "[0.7344973 0.788117 ]\n",
      "[0.85434675 0.8938499 ]\n",
      "[0.8641401 0.8897783]\n",
      "[0.6910065  0.74754614]\n",
      "[0.8561054  0.88679045]\n",
      "[0.8866777 0.9302531]\n",
      "[0.77758086 0.816798  ]\n",
      "[0.7588094 0.8082293]\n",
      "[0.93115497 0.96222156]\n",
      "[0.84370565 0.88494927]\n",
      "[0.8565313 0.8974118]\n",
      "[0.84434694 0.8703099 ]\n",
      "[0.77040344 0.820116  ]\n",
      "[0.78362644 0.8109978 ]\n",
      "[0.8528785 0.8921426]\n",
      "[0.7940591 0.8302913]\n",
      "[0.7913409 0.8330689]\n",
      "[0.8003901 0.8192491]\n",
      "[0.7761973 0.8157359]\n",
      "[0.7390335 0.7773143]\n",
      "[0.8400128 0.8914762]\n",
      "[0.79223   0.8279977]\n",
      "[0.8425903 0.8799159]\n",
      "[0.7450459 0.8011385]\n",
      "[0.8432751 0.8731727]\n",
      "[0.8873692  0.92957085]\n",
      "[0.78722423 0.84534067]\n",
      "[0.8362439 0.8907977]\n",
      "[0.84826225 0.8828436 ]\n",
      "[0.8208861 0.866664 ]\n",
      "[0.79480207 0.8347965 ]\n",
      "[0.8469085  0.87612647]\n",
      "[0.8397941 0.8701659]\n",
      "[0.8474992 0.8725901]\n",
      "[0.7382437 0.7667846]\n",
      "[0.9096083 0.9469256]\n",
      "[0.69087094 0.7570123 ]\n",
      "[0.7749128 0.8251143]\n",
      "[0.7316926 0.7786482]\n",
      "[0.83253473 0.87432486]\n",
      "[0.7047152 0.7620391]\n",
      "[0.79246104 0.835914  ]\n",
      "[0.7456095 0.7861203]\n",
      "[0.69014734 0.74539244]\n",
      "[0.9015168  0.92789227]\n",
      "[0.7554514 0.8160679]\n",
      "[0.8275569 0.855921 ]\n",
      "[0.7605657 0.8122946]\n",
      "[0.87258    0.91327184]\n",
      "[0.90095127 0.9396935 ]\n",
      "[0.7083486  0.74818295]\n",
      "[0.9064946  0.94135445]\n",
      "[0.81025475 0.8526735 ]\n",
      "[0.81160265 0.85392696]\n",
      "[0.7643654  0.81527555]\n",
      "[0.8361438  0.87164086]\n",
      "[0.8526098  0.89979345]\n",
      "[0.9261026 0.9558612]\n",
      "[0.80058795 0.83387476]\n",
      "[0.8138207 0.8549459]\n",
      "[0.8420434  0.85976607]\n",
      "[0.7967821  0.81738394]\n",
      "[0.8262493  0.86347777]\n",
      "[0.8258546  0.85543245]\n",
      "[0.82575184 0.8659957 ]\n",
      "[0.8368555 0.8790654]\n",
      "[0.8421141 0.8785848]\n",
      "[0.906751   0.95377487]\n",
      "[0.82773465 0.8776    ]\n",
      "[0.8870048 0.9172215]\n",
      "[0.7567528 0.7993346]\n",
      "[0.8648257 0.9259197]\n",
      "[0.8231291 0.8498022]\n",
      "[0.7784857 0.8278896]\n",
      "[0.7750719 0.8168923]\n",
      "[0.82539064 0.8579585 ]\n",
      "[0.71797764 0.75109094]\n",
      "[0.83014697 0.8594033 ]\n",
      "[0.8377074 0.8685114]\n",
      "[0.7767852  0.82116294]\n",
      "[0.8439721 0.8803879]\n",
      "[0.7957981  0.84431976]\n",
      "[0.8338188  0.87071794]\n",
      "[0.81968826 0.8707563 ]\n",
      "[0.8430799  0.87641054]\n",
      "[0.7606856  0.79532033]\n",
      "[0.8464118 0.8794237]\n",
      "[0.8005263  0.83793813]\n",
      "[0.83801305 0.8798315 ]\n",
      "[0.75494486 0.8017895 ]\n",
      "[0.7668033  0.79584974]\n",
      "[0.86728317 0.90079826]\n",
      "[0.77968514 0.8279781 ]\n",
      "[0.7274756  0.77553505]\n",
      "[0.8103183 0.8615877]\n",
      "[0.8678656  0.90259707]\n",
      "[0.7804541 0.8127447]\n",
      "[0.84362715 0.87189597]\n",
      "[0.7660858  0.78265905]\n",
      "[0.80885315 0.8479466 ]\n",
      "[0.7724133 0.8157911]\n",
      "[0.80341333 0.83623445]\n",
      "[0.6850452 0.7172933]\n",
      "[0.85020375 0.89678764]\n",
      "[0.79034287 0.8412472 ]\n",
      "[0.8525918 0.8791608]\n",
      "[0.7990411 0.8373893]\n",
      "[0.7939804 0.8625976]\n",
      "[0.70716244 0.76156646]\n",
      "[0.7845319 0.8216679]\n",
      "[0.7435936 0.7728647]\n",
      "[0.7251421  0.77975285]\n",
      "[0.8250572  0.84934705]\n",
      "[0.8172192  0.85288066]\n",
      "[0.7566158  0.81003386]\n",
      "[0.77996284 0.83483475]\n",
      "[0.85038126 0.8769472 ]\n",
      "[0.7474243 0.7857425]\n",
      "[0.78159004 0.82991016]\n",
      "[0.8519588  0.88528055]\n",
      "[0.7526143  0.80352396]\n",
      "[0.80218965 0.8430825 ]\n",
      "[0.8262022  0.87288386]\n",
      "[0.80724335 0.8582924 ]\n",
      "[0.80690974 0.8389614 ]\n",
      "[0.90095335 0.9399095 ]\n",
      "[0.8121544 0.8390251]\n",
      "[0.80550486 0.8332193 ]\n",
      "[0.8413531  0.89011645]\n",
      "[0.7388676 0.7938415]\n",
      "[0.8487204 0.8919868]\n",
      "[0.9282519 0.9682817]\n",
      "[0.8383487 0.8827816]\n",
      "[0.87805194 0.9146034 ]\n",
      "[0.81228524 0.86055046]\n",
      "[0.8530504 0.8866759]\n",
      "[0.7277167 0.7863184]\n",
      "[0.80086815 0.8517326 ]\n",
      "[0.7952091 0.8378317]\n",
      "[0.8321177  0.86969286]\n",
      "[0.8137809  0.84692013]\n",
      "[0.8336782  0.85386354]\n",
      "[0.765075  0.8298237]\n",
      "[0.83652437 0.8899873 ]\n",
      "[0.7849835 0.833031 ]\n",
      "[0.8509434 0.892759 ]\n",
      "[0.8336987 0.8550884]\n",
      "[0.77222675 0.8124098 ]\n",
      "[0.8412956 0.8728498]\n",
      "[0.80477935 0.8424136 ]\n",
      "[0.869943   0.91040534]\n",
      "[0.80721325 0.8473551 ]\n",
      "[0.70303637 0.7449656 ]\n",
      "[0.83633673 0.8757288 ]\n",
      "[0.8373347 0.8716056]\n",
      "[0.69366723 0.7465336 ]\n",
      "[0.82624143 0.8789564 ]\n",
      "[0.8557096  0.92326635]\n",
      "[0.8447698 0.8826044]\n",
      "[0.89460075 0.93093425]\n",
      "[0.83082956 0.8615559 ]\n",
      "[0.81902033 0.8533173 ]\n",
      "[0.7724527  0.80835974]\n",
      "[0.81062025 0.85534436]\n",
      "[0.83626384 0.8893518 ]\n",
      "[0.7992243  0.84558886]\n",
      "[0.82263976 0.8564941 ]\n",
      "[0.7989333 0.8633141]\n",
      "[0.8188213  0.86889833]\n",
      "[0.8790305 0.9046127]\n",
      "[0.7712455 0.8296658]\n",
      "[0.7359163 0.7673957]\n",
      "[0.8234251  0.84702605]\n",
      "[0.80799335 0.8631499 ]\n",
      "[0.8511353 0.9062535]\n",
      "[0.8356794 0.8852224]\n",
      "[0.841395   0.88226646]\n",
      "[0.8266919  0.84923226]\n",
      "[0.9319263  0.97956437]\n",
      "[0.87856907 0.9053752 ]\n",
      "[0.86725336 0.9037835 ]\n",
      "[0.71163625 0.7695202 ]\n",
      "[0.7971156  0.82398885]\n",
      "[0.84310764 0.8808047 ]\n",
      "[0.8251143 0.8557572]\n",
      "[0.8354097 0.8784501]\n",
      "[0.8134578  0.84548205]\n",
      "[0.82525516 0.8667629 ]\n",
      "[0.7463907  0.78262925]\n",
      "[0.8549674  0.90168554]\n",
      "[0.81575316 0.87058526]\n",
      "[0.8165313 0.8552963]\n",
      "[0.8978384 0.9560829]\n",
      "[0.8434182 0.869441 ]\n",
      "[0.8365466 0.8739032]\n",
      "[0.8110667 0.8433974]\n",
      "[0.8585296 0.8897335]\n",
      "[0.7633222  0.81631595]\n",
      "[0.8195202 0.8637933]\n",
      "[0.81950766 0.85722   ]\n",
      "[0.8206652 0.8610609]\n",
      "[0.76639026 0.80194545]\n",
      "[0.87720245 0.90951365]\n",
      "[0.8224693  0.85582787]\n",
      "[0.9526979 0.992845 ]\n",
      "[0.7499687 0.7837641]\n",
      "[0.82710236 0.8693294 ]\n",
      "[0.77844596 0.81887025]\n",
      "[0.78488344 0.8143205 ]\n",
      "[0.77986765 0.8175557 ]\n",
      "[0.88785344 0.92275596]\n",
      "[0.76521707 0.8076187 ]\n",
      "[0.7716963 0.8169399]\n",
      "[0.8723107  0.91272026]\n",
      "[0.8193788  0.86845523]\n",
      "[0.86547273 0.90258044]\n",
      "[0.74942356 0.79766726]\n",
      "[0.8217627 0.853657 ]\n",
      "[0.7949515 0.8274266]\n",
      "[0.7725304  0.80092984]\n",
      "[0.8680574 0.9069756]\n",
      "[0.8652118 0.9048112]\n",
      "[0.8231937 0.8817584]\n",
      "[0.9105386  0.97104067]\n",
      "[0.8100697  0.84530574]\n",
      "[0.870706  0.9160511]\n",
      "[0.7586676  0.80061525]\n",
      "[0.7946134 0.8412885]\n",
      "[0.77967066 0.80971503]\n",
      "[0.79147035 0.8244745 ]\n",
      "[0.8361971 0.8709409]\n",
      "[0.7545548 0.8043674]\n",
      "[0.7518868 0.8122584]\n",
      "[0.7378736  0.77806574]\n",
      "[0.8491466 0.9114828]\n",
      "[0.90997404 0.9613141 ]\n",
      "[0.8658976 0.9121817]\n",
      "[0.9208117 0.9638092]\n",
      "[0.82436526 0.8689148 ]\n",
      "[0.68227524 0.73466724]\n",
      "[0.8121913 0.8640128]\n",
      "[0.90107816 0.9438191 ]\n",
      "[0.837545  0.8668162]\n",
      "[0.8021139 0.8429725]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(val_dataset.X)\n",
    "for prediction in predictions:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
