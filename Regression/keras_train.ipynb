{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "import uproot_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_arrays(a, keys, axis=-1):\n",
    "    flat_arr = np.stack([a[k].flatten() for k in keys], axis=axis)\n",
    "    return awkward.JaggedArray.fromcounts(a[keys[0]].counts, flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(a, maxlen, value=0., dtype='float32'):\n",
    "    x = (np.ones((len(a), maxlen)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(a):\n",
    "        if not len(s):\n",
    "            continue\n",
    "        trunc = s[:maxlen].astype(dtype)\n",
    "        x[idx, :len(trunc)] = trunc\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##and Professor suggests that we could use mass, classifacation for later application\n",
    "def SetAKArr(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    n_particles_ls = []\n",
    "    px_ls = []\n",
    "    py_ls = []\n",
    "    pz_ls = []\n",
    "    energy_ls = []\n",
    "    mass_ls = []\n",
    "    charge_ls = []\n",
    "    _label1 = []\n",
    "    _label2 = []\n",
    "    _label3 = []\n",
    "    _label4 = []\n",
    "    _label5 = []\n",
    "    \n",
    "    n = 0\n",
    "    for line in lines:\n",
    "        if line.startswith('E'):\n",
    "            if not n == 0:\n",
    "                n_particles_ls.append(n)\n",
    "                n = 0\n",
    "            exp_inf = line.split()\n",
    "#             _label1.append(int(exp_inf[1]))\n",
    "#             _label2.append(1-int(exp_inf[1]))\n",
    "#             _label1.append(1)\n",
    "#             _label2.append(0)\n",
    "            _label1.append(float(exp_inf[1]))\n",
    "            _label2.append(float(exp_inf[2]))\n",
    "            _label3.append(float(exp_inf[3]))\n",
    "            _label4.append(float(exp_inf[4]))\n",
    "            _label5.append(float(exp_inf[5]))\n",
    "        else:\n",
    "            par = line.split()\n",
    "            ##particle +1\n",
    "            n = n + 1\n",
    "            px_ls.append(abs(float(par[2])))\n",
    "            py_ls.append(abs(float(par[3])))\n",
    "            pz_ls.append(abs(float(par[4])))\n",
    "            energy_ls.append(abs(float(par[5])))\n",
    "            mass_ls.append(abs(float(par[6])))  \n",
    "            charge_ls.append(int(par[0]))\n",
    "#             px_ls.append(6)\n",
    "#             py_ls.append(2)\n",
    "#             pz_ls.append(3)\n",
    "#             energy_ls.append(4)\n",
    "#             mass_ls.append(5)\n",
    "    if not n == 0:\n",
    "        n_particles_ls.append(n)\n",
    "    px_arr = np.array(px_ls)\n",
    "    py_arr = np.array(py_ls)\n",
    "    pz_arr = np.array(pz_ls)\n",
    "    energy_arr = np.array(energy_ls)\n",
    "    mass_arr = np.array(mass_ls)\n",
    "    charge_arr = np.array(charge_ls)\n",
    "    n_particles = np.array(n_particles_ls)\n",
    "\n",
    "#     print(n_particles)\n",
    "    px = ak.JaggedArray.fromcounts(n_particles, px_arr)\n",
    "    py = ak.JaggedArray.fromcounts(n_particles, py_arr)\n",
    "    pz = ak.JaggedArray.fromcounts(n_particles, pz_arr)\n",
    "    energy = ak.JaggedArray.fromcounts(n_particles, energy_arr)\n",
    "    mass = ak.JaggedArray.fromcounts(n_particles, mass_arr)\n",
    "    charge = ak.JaggedArray.fromcounts(n_particles, charge_arr)\n",
    "    p4 = uproot_methods.TLorentzVectorArray.from_cartesian(px, py, pz, energy)\n",
    "    ##Create an Order Dic\n",
    "    from collections import OrderedDict\n",
    "    v = OrderedDict()\n",
    "    v['part_px'] = px\n",
    "#     print(px)\n",
    "    v['part_py'] = py\n",
    "    v['part_pz'] = pz\n",
    "    v['part_energy'] = energy\n",
    "    v['part_mass'] = mass\n",
    "    v['charge'] = charge\n",
    "    v['part_e_log'] = np.log(energy)\n",
    "    v['part_px_log'] = np.log(px)\n",
    "    v['part_py_log'] = np.log(py)\n",
    "    v['part_pz_log'] = np.log(pz)\n",
    "    v['part_m_log'] = np.log(mass)\n",
    "#     ls1 = [1,2,3,4]\n",
    "#     ls2 = [5,6,7,8]\n",
    "#     v['label'] = np.stack((_label1, _label2, _label3, _label4, _label5), axis=-1)\n",
    "#     print(v['label'])\n",
    "#     v['label'] = np.stack((_label1, _label2, _label3, _label4, _label5), axis = -1)\n",
    "    v['label'] = np.stack(_label5, axis = -1)\n",
    "#     print(v['label'])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, filepath, feature_dict = {}, label = 'label', pad_len=100, data_format='channel_first'):\n",
    "        self.filepath = filepath\n",
    "        self.feature_dict = feature_dict\n",
    "        if len(feature_dict) == 0:\n",
    "            feature_dict['points'] = ['part_px','part_py','part_pz']\n",
    "            feature_dict['features'] = ['part_energy', 'part_mass', 'charge', 'part_px', 'part_py', 'part_pz']\n",
    "            feature_dict['mask'] = ['part_energy']\n",
    "        ##currently we use 'E' for experiments\n",
    "        self.label = label\n",
    "        self.pad_len = pad_len\n",
    "        assert data_format in ('channel_first', 'channel_last')\n",
    "        self.stack_axis = 1 if data_format=='channel_first' else -1\n",
    "        self._values = {}\n",
    "        self._label = None\n",
    "        self._load()\n",
    "        \n",
    "    def _load(self):\n",
    "        logging.info('Start loading file %s' % self.filepath)\n",
    "#         counts = None\n",
    "        a = SetAKArr(self.filepath)\n",
    "        self._label = a[self.label]\n",
    "        for k in self.feature_dict:\n",
    "                cols = self.feature_dict[k]\n",
    "                if not isinstance(cols, (list, tuple)):\n",
    "                    cols = [cols]\n",
    "                arrs = []\n",
    "                for col in cols:\n",
    "                    arrs.append(pad_array(a[col], self.pad_len))\n",
    "                    ##check the dimesion of a[col], and it should be array.\n",
    "                self._values[k] = np.stack(arrs, axis=self.stack_axis)\n",
    "        logging.info('Finished loading file %s' % self.filepath)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key==self.label:\n",
    "            return self._label\n",
    "        else:\n",
    "            return self._values[key]\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._values\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._label\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        shuffle_indices = np.arange(self.__len__())\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        for k in self._values:\n",
    "            self._values[k] = self._values[k][shuffle_indices]\n",
    "        self._label = self._label[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:51:47,299] INFO: Start loading file train.txt\n",
      "/home/htk/miniforge3/envs/tensorflow/lib/python3.5/site-packages/awkward/array/jagged.py:976: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "[2024-03-03 10:51:47,482] INFO: Finished loading file train.txt\n",
      "[2024-03-03 10:51:47,483] INFO: Start loading file val.txt\n",
      "[2024-03-03 10:51:47,506] INFO: Finished loading file val.txt\n",
      "[2024-03-03 10:51:47,507] INFO: Start loading file test.txt\n",
      "[2024-03-03 10:51:47,529] INFO: Finished loading file test.txt\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset('train.txt', data_format='channel_last')\n",
    "val_dataset = Dataset('val.txt', data_format='channel_last')\n",
    "test_dataset = Dataset('test.txt', data_format = 'channel_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tf_keras_model import get_particle_net, get_particle_net_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'particle_net_lite' # choose between 'particle_net' and 'particle_net_lite'\n",
    "##this shows the number of classes for classification\n",
    "# num_classes = train_dataset.y.shape[1]\n",
    "num_classes = 1\n",
    "# print(num_classes)\n",
    "input_shapes = {k:train_dataset[k].shape[1:] for k in train_dataset.X}\n",
    "if 'lite' in model_type:\n",
    "    model = get_particle_net_lite(num_classes, input_shapes)\n",
    "else:\n",
    "    model = get_particle_net(num_classes, input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 1024 if 'lite' in model_type else 384\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 10:\n",
    "        lr *= 0.1\n",
    "    elif epoch > 20:\n",
    "        lr *= 0.01\n",
    "    logging.info('Learning rate: %f'%lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:51:53,232] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ParticleNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mask (InputLayer)               [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_NotEqual_1 (TensorF [(None, 100, 1)]     0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_2 (TensorFlowO [(None, 100, 1)]     0           tf_op_layer_NotEqual_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal_1 (TensorFlow [(None, 100, 1)]     0           tf_op_layer_Cast_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_3 (TensorFlowO [(None, 100, 1)]     0           tf_op_layer_Equal_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_8 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Cast_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "points (InputLayer)             [(None, 100, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_2 (TensorFlowOp [(None, 100, 3)]     0           tf_op_layer_Mul_8[0][0]          \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 100, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_4 (Tensor [(None, 3, 100)]     0           tf_op_layer_Add_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_7 (Tenso [(None, 100, 1, 6)]  0           features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_9 (TensorFlowOp [(None, 100, 3)]     0           tf_op_layer_Add_2[0][0]          \n",
      "                                                                 tf_op_layer_Add_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_2 (Te [(None, 100, 100)]   0           tf_op_layer_Add_2[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_10 (TensorFlowO [(None, 100, 3)]     0           tf_op_layer_Add_2[0][0]          \n",
      "                                                                 tf_op_layer_Add_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_fts_bn (BatchNormal (None, 100, 1, 6)    24          tf_op_layer_ExpandDims_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_4 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_11 (TensorFlowO [(None, 100, 100)]   0           tf_op_layer_BatchMatMulV2_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_5 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_3 (TensorFl [(None, 100, 6)]     0           ParticleNet_fts_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_4 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sum_4[0][0]          \n",
      "                                                                 tf_op_layer_Mul_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_5 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(3,)]               0           tf_op_layer_Squeeze_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(None, 100, 100)]   0           tf_op_layer_Sub_4[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_AddV2_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_2 (TensorFlow [(None,)]            0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2_2 (TensorFlo [(None, 100, 8), (No 0           tf_op_layer_Neg_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 1, 1, 1)]    0           tf_op_layer_Range_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 100, 7)]     0           tf_op_layer_TopKV2_2[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_4 (TensorFlowO [(None, 100, 7, 1)]  0           tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_8 (Tenso [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_9 (Tenso [(None, 100, 1, 6)]  0           tf_op_layer_Squeeze_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_4 (TensorFlo [(None, 100, 7, 2)]  0           tf_op_layer_Tile_4[0][0]         \n",
      "                                                                 tf_op_layer_ExpandDims_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_5 (TensorFlowO [(None, 100, 7, 6)]  0           tf_op_layer_ExpandDims_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_2 (TensorF [(None, 100, 7, 6)]  0           tf_op_layer_Squeeze_3[0][0]      \n",
      "                                                                 tf_op_layer_concat_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_5 (TensorFlowOp [(None, 100, 7, 6)]  0           tf_op_layer_GatherNd_2[0][0]     \n",
      "                                                                 tf_op_layer_Tile_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_5 (TensorFlo [(None, 100, 7, 12)] 0           tf_op_layer_Tile_5[0][0]         \n",
      "                                                                 tf_op_layer_Sub_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv0 (Co (None, 100, 7, 32)   384         tf_op_layer_concat_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn0 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act0 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv1 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn1 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act1 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_10 (Tens [(None, 100, 1, 6)]  0           tf_op_layer_Squeeze_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv2 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_conv ( (None, 100, 1, 32)   192         tf_op_layer_ExpandDims_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn2 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_bn (Ba (None, 100, 1, 32)   128         ParticleNet_EdgeConv0_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act2 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_4 (TensorFl [(None, 100, 32)]    0           ParticleNet_EdgeConv0_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_3 (TensorFlowO [(None, 100, 32)]    0           ParticleNet_EdgeConv0_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorFlow [(None, 100, 32)]    0           tf_op_layer_Squeeze_4[0][0]      \n",
      "                                                                 tf_op_layer_Mean_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_act (A (None, 100, 32)      0           tf_op_layer_AddV2_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_3 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Mul_8[0][0]          \n",
      "                                                                 ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_6 (Tensor [(None, 32, 100)]    0           tf_op_layer_Add_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_12 (TensorFlowO [(None, 100, 32)]    0           tf_op_layer_Add_3[0][0]          \n",
      "                                                                 tf_op_layer_Add_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_3 (Te [(None, 100, 100)]   0           tf_op_layer_Add_3[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_6[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_13 (TensorFlowO [(None, 100, 32)]    0           tf_op_layer_Add_3[0][0]          \n",
      "                                                                 tf_op_layer_Add_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_6 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_12[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_14 (TensorFlowO [(None, 100, 100)]   0           tf_op_layer_BatchMatMulV2_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_7 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_13[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_6 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sum_6[0][0]          \n",
      "                                                                 tf_op_layer_Mul_14[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_7 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(3,)]               0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_6 (TensorFlow [(None, 100, 100)]   0           tf_op_layer_Sub_6[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_7[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_3 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_AddV2_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_3 (TensorFlow [(None,)]            0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2_3 (TensorFlo [(None, 100, 8), (No 0           tf_op_layer_Neg_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 1, 1, 1)]    0           tf_op_layer_Range_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 100, 7)]     0           tf_op_layer_TopKV2_3[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_6 (TensorFlowO [(None, 100, 7, 1)]  0           tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_11 (Tens [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_12 (Tens [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo [(None, 100, 7, 2)]  0           tf_op_layer_Tile_6[0][0]         \n",
      "                                                                 tf_op_layer_ExpandDims_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_7 (TensorFlowO [(None, 100, 7, 32)] 0           tf_op_layer_ExpandDims_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_3 (TensorF [(None, 100, 7, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "                                                                 tf_op_layer_concat_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_7 (TensorFlowOp [(None, 100, 7, 32)] 0           tf_op_layer_GatherNd_3[0][0]     \n",
      "                                                                 tf_op_layer_Tile_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_7 (TensorFlo [(None, 100, 7, 64)] 0           tf_op_layer_Tile_7[0][0]         \n",
      "                                                                 tf_op_layer_Sub_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv0 (Co (None, 100, 7, 64)   4096        tf_op_layer_concat_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn0 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act0 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv1 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn1 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act1 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_13 (Tens [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv2 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_conv ( (None, 100, 1, 64)   2048        tf_op_layer_ExpandDims_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn2 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_bn (Ba (None, 100, 1, 64)   256         ParticleNet_EdgeConv1_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act2 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_5 (TensorFl [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_4 (TensorFlowO [(None, 100, 64)]    0           ParticleNet_EdgeConv1_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_7 (TensorFlow [(None, 100, 64)]    0           tf_op_layer_Squeeze_5[0][0]      \n",
      "                                                                 tf_op_layer_Mean_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_act (A (None, 100, 64)      0           tf_op_layer_AddV2_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_15 (TensorFlowO [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_act[0][0\n",
      "                                                                 tf_op_layer_Cast_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_5 (TensorFlowO [(None, 64)]         0           tf_op_layer_Mul_15[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          8320        tf_op_layer_Mean_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,969\n",
      "Trainable params: 26,189\n",
      "Non-trainable params: 780\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "#               metrics=['accuracy'])\n",
    "model.compile(loss='log_cosh',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss='mean_squared_error',\n",
    "#               optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "#               metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "class LossLogger(Callback):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.filename = filename\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        with open(self.filename, 'a') as f:\n",
    "#             print(\"Epoch \", epoch + 1,\": loss = \", logs[\"val_loss\"], \"\\n\", file = f)\n",
    "#             if (epoch+1)%5==0 or epoch==0:\n",
    "            print(logs[\"val_loss\"], file = f)\n",
    "#             f.write()\n",
    "loss_logger = LossLogger('loss_log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "import os\n",
    "save_dir = 'model_checkpoints'\n",
    "model_name = '%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "# checkpoint = keras.callbacks.ModelCheckpoint(filepath='loss.txt',\n",
    "#                              monitor='val_acc',\n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True)\n",
    "#I change the monitor from val_acc to val_loss\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "progress_bar = keras.callbacks.ProgbarLogger()\n",
    "callbacks = [checkpoint, lr_scheduler, loss_logger]\n",
    "# callbacks = [lr_schedule]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:51:56,584] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 4.2870\n",
      "Epoch 00001: val_loss improved from inf to 4.48587, saving model to model_checkpoints/particle_net_lite_model.001.h5\n",
      "5/5 [==============================] - 3s 649ms/step - accuracy: 0.0000e+00 - loss: 4.2870 - val_accuracy: 0.0000e+00 - val_loss: 4.4859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:01,506] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 3.4625\n",
      "Epoch 00002: val_loss improved from 4.48587 to 4.37961, saving model to model_checkpoints/particle_net_lite_model.002.h5\n",
      "5/5 [==============================] - 3s 622ms/step - accuracy: 0.0000e+00 - loss: 3.4625 - val_accuracy: 0.0000e+00 - val_loss: 4.3796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:05,516] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 2.5400\n",
      "Epoch 00003: val_loss improved from 4.37961 to 4.24895, saving model to model_checkpoints/particle_net_lite_model.003.h5\n",
      "5/5 [==============================] - 3s 613ms/step - accuracy: 0.0000e+00 - loss: 2.5400 - val_accuracy: 0.0000e+00 - val_loss: 4.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:09,467] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 1.4972\n",
      "Epoch 00004: val_loss improved from 4.24895 to 4.07903, saving model to model_checkpoints/particle_net_lite_model.004.h5\n",
      "5/5 [==============================] - 3s 611ms/step - accuracy: 0.0000e+00 - loss: 1.4972 - val_accuracy: 0.0000e+00 - val_loss: 4.0790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:13,399] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.5349\n",
      "Epoch 00005: val_loss improved from 4.07903 to 3.87107, saving model to model_checkpoints/particle_net_lite_model.005.h5\n",
      "5/5 [==============================] - 3s 622ms/step - accuracy: 0.0000e+00 - loss: 0.5349 - val_accuracy: 0.0000e+00 - val_loss: 3.8711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:17,394] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.2943\n",
      "Epoch 00006: val_loss improved from 3.87107 to 3.72747, saving model to model_checkpoints/particle_net_lite_model.006.h5\n",
      "5/5 [==============================] - 3s 644ms/step - accuracy: 0.0000e+00 - loss: 0.2943 - val_accuracy: 0.0000e+00 - val_loss: 3.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:21,549] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.3154\n",
      "Epoch 00007: val_loss improved from 3.72747 to 3.71910, saving model to model_checkpoints/particle_net_lite_model.007.h5\n",
      "5/5 [==============================] - 3s 626ms/step - accuracy: 0.0000e+00 - loss: 0.3154 - val_accuracy: 0.0000e+00 - val_loss: 3.7191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:25,616] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.1364\n",
      "Epoch 00008: val_loss did not improve from 3.71910\n",
      "5/5 [==============================] - 3s 625ms/step - accuracy: 0.0000e+00 - loss: 0.1364 - val_accuracy: 0.0000e+00 - val_loss: 3.7483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:29,653] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.1246\n",
      "Epoch 00009: val_loss did not improve from 3.71910\n",
      "5/5 [==============================] - 3s 625ms/step - accuracy: 0.0000e+00 - loss: 0.1246 - val_accuracy: 0.0000e+00 - val_loss: 3.7335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:33,706] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0985\n",
      "Epoch 00010: val_loss improved from 3.71910 to 3.67811, saving model to model_checkpoints/particle_net_lite_model.010.h5\n",
      "5/5 [==============================] - 3s 624ms/step - accuracy: 0.0000e+00 - loss: 0.0985 - val_accuracy: 0.0000e+00 - val_loss: 3.6781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:37,744] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0692\n",
      "Epoch 00011: val_loss improved from 3.67811 to 3.62113, saving model to model_checkpoints/particle_net_lite_model.011.h5\n",
      "5/5 [==============================] - 3s 641ms/step - accuracy: 0.0000e+00 - loss: 0.0692 - val_accuracy: 0.0000e+00 - val_loss: 3.6211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:41,848] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0705\n",
      "Epoch 00012: val_loss improved from 3.62113 to 3.60227, saving model to model_checkpoints/particle_net_lite_model.012.h5\n",
      "5/5 [==============================] - 3s 631ms/step - accuracy: 0.0000e+00 - loss: 0.0705 - val_accuracy: 0.0000e+00 - val_loss: 3.6023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:45,931] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0691\n",
      "Epoch 00013: val_loss improved from 3.60227 to 3.58290, saving model to model_checkpoints/particle_net_lite_model.013.h5\n",
      "5/5 [==============================] - 3s 645ms/step - accuracy: 0.0000e+00 - loss: 0.0691 - val_accuracy: 0.0000e+00 - val_loss: 3.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:50,102] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0669\n",
      "Epoch 00014: val_loss improved from 3.58290 to 3.56249, saving model to model_checkpoints/particle_net_lite_model.014.h5\n",
      "5/5 [==============================] - 3s 616ms/step - accuracy: 0.0000e+00 - loss: 0.0669 - val_accuracy: 0.0000e+00 - val_loss: 3.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:54,110] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0636\n",
      "Epoch 00015: val_loss improved from 3.56249 to 3.54080, saving model to model_checkpoints/particle_net_lite_model.015.h5\n",
      "5/5 [==============================] - 3s 627ms/step - accuracy: 0.0000e+00 - loss: 0.0636 - val_accuracy: 0.0000e+00 - val_loss: 3.5408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:52:58,148] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0628\n",
      "Epoch 00016: val_loss improved from 3.54080 to 3.51720, saving model to model_checkpoints/particle_net_lite_model.016.h5\n",
      "5/5 [==============================] - 3s 653ms/step - accuracy: 0.0000e+00 - loss: 0.0628 - val_accuracy: 0.0000e+00 - val_loss: 3.5172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:02,353] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0609\n",
      "Epoch 00017: val_loss improved from 3.51720 to 3.49165, saving model to model_checkpoints/particle_net_lite_model.017.h5\n",
      "5/5 [==============================] - 3s 662ms/step - accuracy: 0.0000e+00 - loss: 0.0609 - val_accuracy: 0.0000e+00 - val_loss: 3.4917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:06,598] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0589\n",
      "Epoch 00018: val_loss improved from 3.49165 to 3.46432, saving model to model_checkpoints/particle_net_lite_model.018.h5\n",
      "5/5 [==============================] - 3s 650ms/step - accuracy: 0.0000e+00 - loss: 0.0589 - val_accuracy: 0.0000e+00 - val_loss: 3.4643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:10,862] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0592\n",
      "Epoch 00019: val_loss improved from 3.46432 to 3.43482, saving model to model_checkpoints/particle_net_lite_model.019.h5\n",
      "5/5 [==============================] - 3s 654ms/step - accuracy: 0.0000e+00 - loss: 0.0592 - val_accuracy: 0.0000e+00 - val_loss: 3.4348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:15,090] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0588\n",
      "Epoch 00020: val_loss improved from 3.43482 to 3.40379, saving model to model_checkpoints/particle_net_lite_model.020.h5\n",
      "5/5 [==============================] - 3s 657ms/step - accuracy: 0.0000e+00 - loss: 0.0588 - val_accuracy: 0.0000e+00 - val_loss: 3.4038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:19,350] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0590\n",
      "Epoch 00021: val_loss improved from 3.40379 to 3.37129, saving model to model_checkpoints/particle_net_lite_model.021.h5\n",
      "5/5 [==============================] - 3s 652ms/step - accuracy: 0.0000e+00 - loss: 0.0590 - val_accuracy: 0.0000e+00 - val_loss: 3.3713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:23,557] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0566\n",
      "Epoch 00022: val_loss improved from 3.37129 to 3.33707, saving model to model_checkpoints/particle_net_lite_model.022.h5\n",
      "5/5 [==============================] - 3s 650ms/step - accuracy: 0.0000e+00 - loss: 0.0566 - val_accuracy: 0.0000e+00 - val_loss: 3.3371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:27,746] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0586\n",
      "Epoch 00023: val_loss improved from 3.33707 to 3.30199, saving model to model_checkpoints/particle_net_lite_model.023.h5\n",
      "5/5 [==============================] - 3s 689ms/step - accuracy: 0.0000e+00 - loss: 0.0586 - val_accuracy: 0.0000e+00 - val_loss: 3.3020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:32,116] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0581\n",
      "Epoch 00024: val_loss improved from 3.30199 to 3.26627, saving model to model_checkpoints/particle_net_lite_model.024.h5\n",
      "5/5 [==============================] - 3s 690ms/step - accuracy: 0.0000e+00 - loss: 0.0581 - val_accuracy: 0.0000e+00 - val_loss: 3.2663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:36,516] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0598\n",
      "Epoch 00025: val_loss improved from 3.26627 to 3.22947, saving model to model_checkpoints/particle_net_lite_model.025.h5\n",
      "5/5 [==============================] - 3s 679ms/step - accuracy: 0.0000e+00 - loss: 0.0598 - val_accuracy: 0.0000e+00 - val_loss: 3.2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:40,880] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0581\n",
      "Epoch 00026: val_loss improved from 3.22947 to 3.19185, saving model to model_checkpoints/particle_net_lite_model.026.h5\n",
      "5/5 [==============================] - 3s 659ms/step - accuracy: 0.0000e+00 - loss: 0.0581 - val_accuracy: 0.0000e+00 - val_loss: 3.1918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:45,157] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0578\n",
      "Epoch 00027: val_loss improved from 3.19185 to 3.15302, saving model to model_checkpoints/particle_net_lite_model.027.h5\n",
      "5/5 [==============================] - 3s 655ms/step - accuracy: 0.0000e+00 - loss: 0.0578 - val_accuracy: 0.0000e+00 - val_loss: 3.1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:49,393] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0559\n",
      "Epoch 00028: val_loss improved from 3.15302 to 3.11386, saving model to model_checkpoints/particle_net_lite_model.028.h5\n",
      "5/5 [==============================] - 3s 649ms/step - accuracy: 0.0000e+00 - loss: 0.0559 - val_accuracy: 0.0000e+00 - val_loss: 3.1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:53,591] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0568\n",
      "Epoch 00029: val_loss improved from 3.11386 to 3.07454, saving model to model_checkpoints/particle_net_lite_model.029.h5\n",
      "5/5 [==============================] - 3s 664ms/step - accuracy: 0.0000e+00 - loss: 0.0568 - val_accuracy: 0.0000e+00 - val_loss: 3.0745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:53:57,856] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "5/5 [==============================] - ETA: 0s - accuracy: 0.0000e+00 - loss: 0.0542\n",
      "Epoch 00030: val_loss improved from 3.07454 to 3.03444, saving model to model_checkpoints/particle_net_lite_model.030.h5\n",
      "5/5 [==============================] - 3s 654ms/step - accuracy: 0.0000e+00 - loss: 0.0542 - val_accuracy: 0.0000e+00 - val_loss: 3.0344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2282d4c400>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shuffle()\n",
    "model.fit(train_dataset.X, train_dataset.y,\n",
    "          batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "          epochs=30, # --- train only for 1 epoch here for demonstration ---\n",
    "          validation_data=(val_dataset.X, val_dataset.y),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2355587]\n",
      "[2.263892]\n",
      "[1.9904692]\n",
      "[2.0716598]\n",
      "[2.1739566]\n",
      "[2.1478882]\n",
      "[2.0731783]\n",
      "[2.1058273]\n",
      "[2.1574616]\n",
      "[2.061681]\n",
      "[2.2142441]\n",
      "[2.153094]\n",
      "[2.0303738]\n",
      "[2.0304387]\n",
      "[2.1040561]\n",
      "[2.1510427]\n",
      "[2.1811533]\n",
      "[2.0896368]\n",
      "[2.156884]\n",
      "[2.0285914]\n",
      "[2.0999713]\n",
      "[2.1493244]\n",
      "[2.1204877]\n",
      "[2.005537]\n",
      "[2.1498725]\n",
      "[2.2014647]\n",
      "[2.1142707]\n",
      "[2.141198]\n",
      "[2.2180314]\n",
      "[2.1213305]\n",
      "[2.1032257]\n",
      "[2.0453799]\n",
      "[2.101873]\n",
      "[2.1368816]\n",
      "[2.1217015]\n",
      "[2.2747025]\n",
      "[2.1699953]\n",
      "[2.1023476]\n",
      "[2.1776586]\n",
      "[2.0868165]\n",
      "[2.1228402]\n",
      "[2.0104]\n",
      "[2.169025]\n",
      "[2.2086189]\n",
      "[2.0947545]\n",
      "[2.1251929]\n",
      "[2.0240119]\n",
      "[2.205694]\n",
      "[2.1174688]\n",
      "[2.2067692]\n",
      "[2.0292854]\n",
      "[2.1025047]\n",
      "[2.106222]\n",
      "[2.0701768]\n",
      "[2.1069267]\n",
      "[2.2311242]\n",
      "[2.2329934]\n",
      "[2.1579502]\n",
      "[2.1621525]\n",
      "[2.1256273]\n",
      "[1.9916127]\n",
      "[1.989718]\n",
      "[2.0969675]\n",
      "[2.0354187]\n",
      "[2.061754]\n",
      "[2.016888]\n",
      "[2.2054718]\n",
      "[2.1494567]\n",
      "[2.0751963]\n",
      "[2.2164342]\n",
      "[2.0571394]\n",
      "[2.092072]\n",
      "[2.1033242]\n",
      "[2.117317]\n",
      "[2.2183459]\n",
      "[2.1128912]\n",
      "[2.1693864]\n",
      "[2.2150085]\n",
      "[2.2009718]\n",
      "[2.1880624]\n",
      "[2.216729]\n",
      "[2.1379833]\n",
      "[2.075752]\n",
      "[2.1628091]\n",
      "[2.144723]\n",
      "[2.1720572]\n",
      "[2.2776003]\n",
      "[2.1029267]\n",
      "[2.1034646]\n",
      "[2.1134994]\n",
      "[2.1059737]\n",
      "[2.0807273]\n",
      "[2.185872]\n",
      "[2.1169727]\n",
      "[2.1107218]\n",
      "[2.2119005]\n",
      "[2.005784]\n",
      "[2.2083778]\n",
      "[2.2274404]\n",
      "[2.1237113]\n",
      "[2.129395]\n",
      "[1.955222]\n",
      "[2.0341394]\n",
      "[2.1088274]\n",
      "[2.112131]\n",
      "[2.2742312]\n",
      "[2.0360022]\n",
      "[2.0989947]\n",
      "[2.1927383]\n",
      "[2.084887]\n",
      "[2.1875594]\n",
      "[2.1382473]\n",
      "[2.1479616]\n",
      "[2.2500255]\n",
      "[2.153761]\n",
      "[2.0686224]\n",
      "[2.1081717]\n",
      "[1.9597995]\n",
      "[2.1377409]\n",
      "[2.1132658]\n",
      "[2.1225016]\n",
      "[2.0967782]\n",
      "[2.1214364]\n",
      "[2.161442]\n",
      "[2.1512072]\n",
      "[2.0382416]\n",
      "[2.112222]\n",
      "[2.0939364]\n",
      "[2.1533592]\n",
      "[2.199945]\n",
      "[2.1236212]\n",
      "[2.1545708]\n",
      "[2.0534859]\n",
      "[2.0833645]\n",
      "[2.1494803]\n",
      "[2.117443]\n",
      "[2.1972768]\n",
      "[1.9900632]\n",
      "[2.2002013]\n",
      "[2.2295513]\n",
      "[2.0613244]\n",
      "[2.126275]\n",
      "[2.1606982]\n",
      "[2.115039]\n",
      "[2.1205597]\n",
      "[2.1317651]\n",
      "[2.1016977]\n",
      "[2.1348653]\n",
      "[2.1371233]\n",
      "[2.142481]\n",
      "[2.1113281]\n",
      "[2.192223]\n",
      "[2.1573586]\n",
      "[2.097027]\n",
      "[2.2365124]\n",
      "[2.0821784]\n",
      "[2.1572661]\n",
      "[2.0785747]\n",
      "[2.061601]\n",
      "[2.2441175]\n",
      "[2.0509427]\n",
      "[2.1117527]\n",
      "[2.1003494]\n",
      "[2.1470678]\n",
      "[2.1096988]\n",
      "[2.1142547]\n",
      "[2.114847]\n",
      "[2.0704534]\n",
      "[2.0969312]\n",
      "[2.111769]\n",
      "[2.142137]\n",
      "[2.0823045]\n",
      "[2.1271322]\n",
      "[2.1773403]\n",
      "[2.2369845]\n",
      "[2.2275422]\n",
      "[2.3142881]\n",
      "[2.0855095]\n",
      "[2.1158214]\n",
      "[2.1092436]\n",
      "[2.117022]\n",
      "[2.1358767]\n",
      "[2.2376075]\n",
      "[2.0598614]\n",
      "[2.1139715]\n",
      "[2.0748992]\n",
      "[2.175321]\n",
      "[2.1483839]\n",
      "[2.2254431]\n",
      "[2.20962]\n",
      "[2.1601403]\n",
      "[2.1269207]\n",
      "[2.1324856]\n",
      "[2.2005365]\n",
      "[2.1179354]\n",
      "[2.1539104]\n",
      "[2.1349664]\n",
      "[2.0775437]\n",
      "[2.2215745]\n",
      "[2.080848]\n",
      "[2.0735555]\n",
      "[2.2701356]\n",
      "[2.1570928]\n",
      "[2.2401907]\n",
      "[2.1326334]\n",
      "[2.1859686]\n",
      "[2.0875952]\n",
      "[2.1109421]\n",
      "[2.0916924]\n",
      "[2.2311296]\n",
      "[2.0347645]\n",
      "[2.1439652]\n",
      "[2.2261834]\n",
      "[2.1254385]\n",
      "[2.1004403]\n",
      "[2.1136596]\n",
      "[2.0872793]\n",
      "[2.1758735]\n",
      "[2.2187467]\n",
      "[2.1693747]\n",
      "[2.205584]\n",
      "[2.1964042]\n",
      "[2.0612082]\n",
      "[2.0837858]\n",
      "[2.1635773]\n",
      "[2.1680303]\n",
      "[2.1017964]\n",
      "[2.1597922]\n",
      "[2.2003796]\n",
      "[2.1714115]\n",
      "[2.0904696]\n",
      "[2.0883691]\n",
      "[2.1631944]\n",
      "[2.1543682]\n",
      "[2.1256158]\n",
      "[2.163149]\n",
      "[2.072084]\n",
      "[2.0380025]\n",
      "[2.122564]\n",
      "[2.181023]\n",
      "[2.0863292]\n",
      "[2.184759]\n",
      "[2.1201217]\n",
      "[2.0773132]\n",
      "[2.1602464]\n",
      "[2.2688851]\n",
      "[2.0772874]\n",
      "[2.105988]\n",
      "[2.1486473]\n",
      "[2.1614273]\n",
      "[2.0882614]\n",
      "[2.193692]\n",
      "[2.0243464]\n",
      "[1.9522401]\n",
      "[2.1067512]\n",
      "[2.0417318]\n",
      "[2.2449543]\n",
      "[2.1089044]\n",
      "[2.1455634]\n",
      "[2.1029341]\n",
      "[2.2260568]\n",
      "[2.0917733]\n",
      "[2.0515125]\n",
      "[2.23877]\n",
      "[1.946672]\n",
      "[2.1665483]\n",
      "[2.109276]\n",
      "[2.097317]\n",
      "[2.130092]\n",
      "[2.0938065]\n",
      "[2.1012757]\n",
      "[2.1144686]\n",
      "[2.199462]\n",
      "[2.051501]\n",
      "[2.265368]\n",
      "[2.0898485]\n",
      "[2.0925066]\n",
      "[2.086965]\n",
      "[2.1538012]\n",
      "[2.180099]\n",
      "[2.1704412]\n",
      "[2.0909176]\n",
      "[2.142929]\n",
      "[2.104524]\n",
      "[2.067407]\n",
      "[2.1720064]\n",
      "[2.2576764]\n",
      "[2.0831423]\n",
      "[2.079647]\n",
      "[2.0593345]\n",
      "[2.110934]\n",
      "[2.0799208]\n",
      "[2.2997682]\n",
      "[2.1977637]\n",
      "[2.1406548]\n",
      "[2.3165786]\n",
      "[2.108526]\n",
      "[2.0854821]\n",
      "[2.0940716]\n",
      "[2.1417341]\n",
      "[2.17514]\n",
      "[2.133293]\n",
      "[2.2205007]\n",
      "[2.1394393]\n",
      "[2.0810032]\n",
      "[1.9862504]\n",
      "[2.117437]\n",
      "[2.2662783]\n",
      "[2.1874602]\n",
      "[2.2126164]\n",
      "[2.0950391]\n",
      "[2.1042666]\n",
      "[2.090808]\n",
      "[2.0351708]\n",
      "[2.1252966]\n",
      "[2.1319525]\n",
      "[2.1327512]\n",
      "[2.104468]\n",
      "[2.1377218]\n",
      "[2.0458884]\n",
      "[2.1752615]\n",
      "[2.025045]\n",
      "[2.250113]\n",
      "[2.096564]\n",
      "[2.1159778]\n",
      "[2.0353725]\n",
      "[2.2010806]\n",
      "[2.1293633]\n",
      "[2.0707061]\n",
      "[2.0472143]\n",
      "[2.0935948]\n",
      "[2.0099134]\n",
      "[2.0968225]\n",
      "[2.150732]\n",
      "[2.1282861]\n",
      "[2.2821324]\n",
      "[2.1595411]\n",
      "[2.2110708]\n",
      "[2.225796]\n",
      "[2.0834835]\n",
      "[2.1089442]\n",
      "[2.059545]\n",
      "[2.0825777]\n",
      "[2.0892355]\n",
      "[2.0879567]\n",
      "[2.152316]\n",
      "[2.1527088]\n",
      "[2.2139692]\n",
      "[2.0332003]\n",
      "[2.1163487]\n",
      "[2.1924956]\n",
      "[2.2896624]\n",
      "[2.0833864]\n",
      "[2.0498364]\n",
      "[2.198468]\n",
      "[2.1356728]\n",
      "[2.1493914]\n",
      "[2.0775435]\n",
      "[2.0927517]\n",
      "[2.1479475]\n",
      "[2.0498374]\n",
      "[2.13794]\n",
      "[2.1053379]\n",
      "[2.121108]\n",
      "[2.102252]\n",
      "[2.051032]\n",
      "[2.0950673]\n",
      "[2.175097]\n",
      "[2.1965902]\n",
      "[2.0670564]\n",
      "[2.116106]\n",
      "[2.143814]\n",
      "[2.0892127]\n",
      "[2.1190104]\n",
      "[2.1459057]\n",
      "[2.248352]\n",
      "[2.2508664]\n",
      "[2.1153448]\n",
      "[2.1196656]\n",
      "[2.1296816]\n",
      "[2.2393534]\n",
      "[2.071029]\n",
      "[2.1956577]\n",
      "[2.1700761]\n",
      "[2.0809128]\n",
      "[2.048673]\n",
      "[2.13249]\n",
      "[2.0989852]\n",
      "[2.1806698]\n",
      "[2.0363955]\n",
      "[2.2428248]\n",
      "[2.035532]\n",
      "[2.1861675]\n",
      "[2.0516663]\n",
      "[2.1775796]\n",
      "[2.1060462]\n",
      "[2.1434453]\n",
      "[2.2780008]\n",
      "[2.1301625]\n",
      "[2.1041808]\n",
      "[2.1075425]\n",
      "[2.092551]\n",
      "[2.0742316]\n",
      "[2.0331001]\n",
      "[2.150111]\n",
      "[2.0804431]\n",
      "[2.1703498]\n",
      "[2.223369]\n",
      "[2.062641]\n",
      "[2.1948507]\n",
      "[2.14759]\n",
      "[2.1198494]\n",
      "[2.119571]\n",
      "[2.221123]\n",
      "[2.1442351]\n",
      "[1.99386]\n",
      "[2.1899357]\n",
      "[2.2418885]\n",
      "[2.0740101]\n",
      "[2.0897753]\n",
      "[2.2000074]\n",
      "[2.1001303]\n",
      "[2.1123066]\n",
      "[2.1046531]\n",
      "[2.1412754]\n",
      "[2.0988019]\n",
      "[2.185312]\n",
      "[2.0265691]\n",
      "[2.1032417]\n",
      "[2.193689]\n",
      "[2.060941]\n",
      "[2.105186]\n",
      "[2.149513]\n",
      "[2.0613136]\n",
      "[2.0936882]\n",
      "[2.2069488]\n",
      "[2.1562498]\n",
      "[2.0994704]\n",
      "[2.103364]\n",
      "[2.166813]\n",
      "[2.128059]\n",
      "[2.1135314]\n",
      "[2.0932934]\n",
      "[2.1215327]\n",
      "[2.1264083]\n",
      "[2.1728241]\n",
      "[2.118114]\n",
      "[2.0820167]\n",
      "[2.161938]\n",
      "[2.1333084]\n",
      "[2.0985668]\n",
      "[2.208534]\n",
      "[2.109864]\n",
      "[2.1286204]\n",
      "[2.2118247]\n",
      "[2.0335197]\n",
      "[2.14945]\n",
      "[1.9938734]\n",
      "[2.1963146]\n",
      "[2.1484358]\n",
      "[2.1559446]\n",
      "[2.0797968]\n",
      "[2.1501987]\n",
      "[2.152288]\n",
      "[2.1488645]\n",
      "[2.0760834]\n",
      "[2.1285]\n",
      "[2.1914473]\n",
      "[2.1099107]\n",
      "[2.1234043]\n",
      "[2.127811]\n",
      "[2.1520646]\n",
      "[2.1121156]\n",
      "[2.1842203]\n",
      "[2.1740808]\n",
      "[2.187704]\n",
      "[2.191219]\n",
      "[2.145926]\n",
      "[2.0270045]\n",
      "[2.085098]\n",
      "[2.1016948]\n",
      "[2.2111986]\n",
      "[2.0805497]\n",
      "[2.0860875]\n",
      "[2.1131647]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_dataset.X)\n",
    "for prediction in predictions:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
