{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "import uproot_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_arrays(a, keys, axis=-1):\n",
    "    flat_arr = np.stack([a[k].flatten() for k in keys], axis=axis)\n",
    "    return awkward.JaggedArray.fromcounts(a[keys[0]].counts, flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(a, maxlen, value=0., dtype='float32'):\n",
    "    x = (np.ones((len(a), maxlen)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(a):\n",
    "        if not len(s):\n",
    "            continue\n",
    "        trunc = s[:maxlen].astype(dtype)\n",
    "        x[idx, :len(trunc)] = trunc\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##and Professor suggests that we could use mass, classifacation for later application\n",
    "def SetAKArr(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    n_particles_ls = []\n",
    "    px_ls = []\n",
    "    py_ls = []\n",
    "    pz_ls = []\n",
    "    energy_ls = []\n",
    "    mass_ls = []\n",
    "    charge_ls = []\n",
    "    _label1 = []\n",
    "    _label2 = []\n",
    "    _label3 = []\n",
    "    _label4 = []\n",
    "    _label5 = []\n",
    "    \n",
    "    n = 0\n",
    "    for line in lines:\n",
    "        if line.startswith('E'):\n",
    "            if not n == 0:\n",
    "                n_particles_ls.append(n)\n",
    "                n = 0\n",
    "            exp_inf = line.split()\n",
    "#             _label1.append(int(exp_inf[1]))\n",
    "#             _label2.append(1-int(exp_inf[1]))\n",
    "#             _label1.append(1)\n",
    "#             _label2.append(0)\n",
    "            _label1.append(float(exp_inf[1]))\n",
    "            _label2.append(float(exp_inf[2]))\n",
    "            _label3.append(float(exp_inf[3]))\n",
    "            _label4.append(float(exp_inf[4]))\n",
    "            _label5.append(float(exp_inf[5]))\n",
    "        else:\n",
    "            par = line.split()\n",
    "            ##particle +1\n",
    "            n = n + 1\n",
    "            px_ls.append(abs(float(par[2])))\n",
    "            py_ls.append(abs(float(par[3])))\n",
    "            pz_ls.append(abs(float(par[4])))\n",
    "            energy_ls.append(abs(float(par[5])))\n",
    "            mass_ls.append(abs(float(par[6])))  \n",
    "            charge_ls.append(int(par[0]))\n",
    "#             px_ls.append(6)\n",
    "#             py_ls.append(2)\n",
    "#             pz_ls.append(3)\n",
    "#             energy_ls.append(4)\n",
    "#             mass_ls.append(5)\n",
    "    if not n == 0:\n",
    "        n_particles_ls.append(n)\n",
    "    px_arr = np.array(px_ls)\n",
    "    py_arr = np.array(py_ls)\n",
    "    pz_arr = np.array(pz_ls)\n",
    "    energy_arr = np.array(energy_ls)\n",
    "    mass_arr = np.array(mass_ls)\n",
    "    charge_arr = np.array(charge_ls)\n",
    "    n_particles = np.array(n_particles_ls)\n",
    "\n",
    "#     print(n_particles)\n",
    "    px = ak.JaggedArray.fromcounts(n_particles, px_arr)\n",
    "    py = ak.JaggedArray.fromcounts(n_particles, py_arr)\n",
    "    pz = ak.JaggedArray.fromcounts(n_particles, pz_arr)\n",
    "    energy = ak.JaggedArray.fromcounts(n_particles, energy_arr)\n",
    "    mass = ak.JaggedArray.fromcounts(n_particles, mass_arr)\n",
    "    charge = ak.JaggedArray.fromcounts(n_particles, charge_arr)\n",
    "    p4 = uproot_methods.TLorentzVectorArray.from_cartesian(px, py, pz, energy)\n",
    "    ##Create an Order Dic\n",
    "    from collections import OrderedDict\n",
    "    v = OrderedDict()\n",
    "    v['part_px'] = px\n",
    "#     print(px)\n",
    "    v['part_py'] = py\n",
    "    v['part_pz'] = pz\n",
    "    v['part_energy'] = energy\n",
    "    v['part_mass'] = mass\n",
    "    v['charge'] = charge\n",
    "    v['part_e_log'] = np.log(energy)\n",
    "    v['part_px_log'] = np.log(px)\n",
    "    v['part_py_log'] = np.log(py)\n",
    "    v['part_pz_log'] = np.log(pz)\n",
    "    v['part_m_log'] = np.log(mass)\n",
    "#     ls1 = [1,2,3,4]\n",
    "#     ls2 = [5,6,7,8]\n",
    "#     v['label'] = np.stack((_label1, _label2, _label3, _label4, _label5), axis=-1)\n",
    "#     print(v['label'])\n",
    "#     v['label'] = np.stack((_label1, _label2, _label3, _label4, _label5), axis = -1)\n",
    "    v['label'] = np.stack(_label5, axis = -1)\n",
    "#     print(v['label'])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, filepath, feature_dict = {}, label = 'label', pad_len=100, data_format='channel_first'):\n",
    "        self.filepath = filepath\n",
    "        self.feature_dict = feature_dict\n",
    "        if len(feature_dict) == 0:\n",
    "            feature_dict['points'] = ['part_px','part_py','part_pz']\n",
    "            feature_dict['features'] = ['part_energy', 'part_mass', 'charge', 'part_px', 'part_py', 'part_pz']\n",
    "            feature_dict['mask'] = ['part_energy']\n",
    "        ##currently we use 'E' for experiments\n",
    "        self.label = label\n",
    "        self.pad_len = pad_len\n",
    "        assert data_format in ('channel_first', 'channel_last')\n",
    "        self.stack_axis = 1 if data_format=='channel_first' else -1\n",
    "        self._values = {}\n",
    "        self._label = None\n",
    "        self._load()\n",
    "        \n",
    "    def _load(self):\n",
    "        logging.info('Start loading file %s' % self.filepath)\n",
    "#         counts = None\n",
    "        a = SetAKArr(self.filepath)\n",
    "        self._label = a[self.label]\n",
    "        for k in self.feature_dict:\n",
    "                cols = self.feature_dict[k]\n",
    "                if not isinstance(cols, (list, tuple)):\n",
    "                    cols = [cols]\n",
    "                arrs = []\n",
    "                for col in cols:\n",
    "                    arrs.append(pad_array(a[col], self.pad_len))\n",
    "                    ##check the dimesion of a[col], and it should be array.\n",
    "                self._values[k] = np.stack(arrs, axis=self.stack_axis)\n",
    "        logging.info('Finished loading file %s' % self.filepath)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key==self.label:\n",
    "            return self._label\n",
    "        else:\n",
    "            return self._values[key]\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._values\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._label\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        shuffle_indices = np.arange(self.__len__())\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        for k in self._values:\n",
    "            self._values[k] = self._values[k][shuffle_indices]\n",
    "        self._label = self._label[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:02,016] INFO: Start loading file train.txt\n",
      "/home/htk/miniforge3/envs/tensorflow/lib/python3.5/site-packages/awkward/array/jagged.py:976: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "[2024-03-04 10:39:02,221] INFO: Finished loading file train.txt\n",
      "[2024-03-04 10:39:02,222] INFO: Start loading file val.txt\n",
      "[2024-03-04 10:39:02,244] INFO: Finished loading file val.txt\n",
      "[2024-03-04 10:39:02,245] INFO: Start loading file test.txt\n",
      "[2024-03-04 10:39:02,267] INFO: Finished loading file test.txt\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset('train.txt', data_format='channel_last')\n",
    "val_dataset = Dataset('val.txt', data_format='channel_last')\n",
    "test_dataset = Dataset('test.txt', data_format = 'channel_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tf_keras_model import get_particle_net, get_particle_net_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'particle_net_lite' # choose between 'particle_net' and 'particle_net_lite'\n",
    "##this shows the number of classes for classification\n",
    "# num_classes = train_dataset.y.shape[1]\n",
    "num_classes = 1\n",
    "# print(num_classes)\n",
    "input_shapes = {k:train_dataset[k].shape[1:] for k in train_dataset.X}\n",
    "if 'lite' in model_type:\n",
    "    model = get_particle_net_lite(num_classes, input_shapes)\n",
    "else:\n",
    "    model = get_particle_net(num_classes, input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 1024 if 'lite' in model_type else 384\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 10:\n",
    "        lr *= 0.1\n",
    "    elif epoch > 20:\n",
    "        lr *= 0.01\n",
    "    logging.info('Learning rate: %f'%lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:07,617] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ParticleNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mask (InputLayer)               [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_NotEqual (TensorFlo [(None, 100, 1)]     0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast (TensorFlowOpL [(None, 100, 1)]     0           tf_op_layer_NotEqual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_1 (TensorFlowO [(None, 100, 1)]     0           tf_op_layer_Equal[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 100, 1)]     0           tf_op_layer_Cast_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "points (InputLayer)             [(None, 100, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add (TensorFlowOpLa [(None, 100, 3)]     0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 100, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose (TensorFl [(None, 3, 100)]     0           tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 100, 1, 6)]  0           features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 100, 3)]     0           tf_op_layer_Add[0][0]            \n",
      "                                                                 tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2 (Tens [(None, 100, 100)]   0           tf_op_layer_Add[0][0]            \n",
      "                                                                 tf_op_layer_Transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_2 (TensorFlowOp [(None, 100, 3)]     0           tf_op_layer_Add[0][0]            \n",
      "                                                                 tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_fts_bn (BatchNormal (None, 100, 1, 6)    24          tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None, 100, 1)]     0           tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_3 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_BatchMatMulV2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 100, 6)]     0           ParticleNet_fts_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 100, 100)]   0           tf_op_layer_Sum[0][0]            \n",
      "                                                                 tf_op_layer_Mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_1 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(3,)]               0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 tf_op_layer_Transpose_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg (TensorFlowOpLa [(None, 100, 100)]   0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range (TensorFlowOp [(None,)]            0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2 (TensorFlowO [(None, 100, 8), (No 0           tf_op_layer_Neg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 1, 1, 1)]    0           tf_op_layer_Range[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 100, 7)]     0           tf_op_layer_TopKV2[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile (TensorFlowOpL [(None, 100, 7, 1)]  0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(None, 100, 1, 6)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 100, 7, 2)]  0           tf_op_layer_Tile[0][0]           \n",
      "                                                                 tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_1 (TensorFlowO [(None, 100, 7, 6)]  0           tf_op_layer_ExpandDims_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd (TensorFlo [(None, 100, 7, 6)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "                                                                 tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 100, 7, 6)]  0           tf_op_layer_GatherNd[0][0]       \n",
      "                                                                 tf_op_layer_Tile_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 100, 7, 12)] 0           tf_op_layer_Tile_1[0][0]         \n",
      "                                                                 tf_op_layer_Sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv0 (Co (None, 100, 7, 32)   384         tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn0 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act0 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv1 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn1 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act1 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_3 (Tenso [(None, 100, 1, 6)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv2 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_conv ( (None, 100, 1, 32)   192         tf_op_layer_ExpandDims_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn2 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_bn (Ba (None, 100, 1, 32)   128         ParticleNet_EdgeConv0_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act2 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_1 (TensorFl [(None, 100, 32)]    0           ParticleNet_EdgeConv0_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 100, 32)]    0           ParticleNet_EdgeConv0_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 100, 32)]    0           tf_op_layer_Squeeze_1[0][0]      \n",
      "                                                                 tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_act (A (None, 100, 32)      0           tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_1 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_2 (Tensor [(None, 32, 100)]    0           tf_op_layer_Add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_4 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Add_1[0][0]          \n",
      "                                                                 tf_op_layer_Add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_1 (Te [(None, 100, 100)]   0           tf_op_layer_Add_1[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_5 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Add_1[0][0]          \n",
      "                                                                 tf_op_layer_Add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_2 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_6 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_BatchMatMulV2_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_3 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sum_2[0][0]          \n",
      "                                                                 tf_op_layer_Mul_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_3 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(3,)]               0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 100, 100)]   0           tf_op_layer_Sub_2[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_1 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_1 (TensorFlow [(None,)]            0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2_1 (TensorFlo [(None, 100, 8), (No 0           tf_op_layer_Neg_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 1, 1, 1)]    0           tf_op_layer_Range_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 100, 7)]     0           tf_op_layer_TopKV2_1[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_2 (TensorFlowO [(None, 100, 7, 1)]  0           tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_4 (Tenso [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_5 (Tenso [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_2 (TensorFlo [(None, 100, 7, 2)]  0           tf_op_layer_Tile_2[0][0]         \n",
      "                                                                 tf_op_layer_ExpandDims_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_3 (TensorFlowO [(None, 100, 7, 32)] 0           tf_op_layer_ExpandDims_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_1 (TensorF [(None, 100, 7, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "                                                                 tf_op_layer_concat_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_3 (TensorFlowOp [(None, 100, 7, 32)] 0           tf_op_layer_GatherNd_1[0][0]     \n",
      "                                                                 tf_op_layer_Tile_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 100, 7, 64)] 0           tf_op_layer_Tile_3[0][0]         \n",
      "                                                                 tf_op_layer_Sub_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv0 (Co (None, 100, 7, 64)   4096        tf_op_layer_concat_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn0 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act0 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv1 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn1 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act1 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_6 (Tenso [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv2 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_conv ( (None, 100, 1, 64)   2048        tf_op_layer_ExpandDims_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn2 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_bn (Ba (None, 100, 1, 64)   256         ParticleNet_EdgeConv1_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act2 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_2 (TensorFl [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [(None, 100, 64)]    0           ParticleNet_EdgeConv1_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 100, 64)]    0           tf_op_layer_Squeeze_2[0][0]      \n",
      "                                                                 tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_act (A (None, 100, 64)      0           tf_op_layer_AddV2_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_7 (TensorFlowOp [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_act[0][0\n",
      "                                                                 tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_2 (TensorFlowO [(None, 64)]         0           tf_op_layer_Mul_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          8320        tf_op_layer_Mean_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,969\n",
      "Trainable params: 26,189\n",
      "Non-trainable params: 780\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "#               metrics=['accuracy'])\n",
    "# model.compile(loss='log_cosh',\n",
    "#               optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "#               metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "class LossLogger(Callback):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.filename = filename\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        with open(self.filename, 'a') as f:\n",
    "#             print(\"Epoch \", epoch + 1,\": loss = \", logs[\"val_loss\"], \"\\n\", file = f)\n",
    "#             if (epoch+1)%5==0 or epoch==0:\n",
    "            print(logs[\"val_loss\"], file = f)\n",
    "#             f.write()\n",
    "loss_logger = LossLogger('loss_log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "import os\n",
    "save_dir = 'model_checkpoints'\n",
    "model_name = '%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "# checkpoint = keras.callbacks.ModelCheckpoint(filepath='loss.txt',\n",
    "#                              monitor='val_acc',\n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True)\n",
    "#I change the monitor from val_acc to val_loss\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "progress_bar = keras.callbacks.ProgbarLogger()\n",
    "callbacks = [checkpoint, lr_scheduler, loss_logger]\n",
    "# callbacks = [lr_schedule]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:11,085] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 23.4355 - accuracy: 0.0000e+00\n",
      "Epoch 00001: val_loss improved from inf to 26.89506, saving model to model_checkpoints/particle_net_lite_model.001.h5\n",
      "5/5 [==============================] - 3s 664ms/step - loss: 23.4355 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 26.8951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:16,208] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 15.7249 - accuracy: 0.0000e+00\n",
      "Epoch 00002: val_loss improved from 26.89506 to 25.91664, saving model to model_checkpoints/particle_net_lite_model.002.h5\n",
      "5/5 [==============================] - 3s 607ms/step - loss: 15.7249 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 25.9166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:20,120] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.8334 - accuracy: 0.0000e+00\n",
      "Epoch 00003: val_loss improved from 25.91664 to 24.66526, saving model to model_checkpoints/particle_net_lite_model.003.h5\n",
      "5/5 [==============================] - 3s 607ms/step - loss: 8.8334 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 24.6653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:24,027] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.4572 - accuracy: 0.0000e+00\n",
      "Epoch 00004: val_loss improved from 24.66526 to 23.08996, saving model to model_checkpoints/particle_net_lite_model.004.h5\n",
      "5/5 [==============================] - 3s 604ms/step - loss: 3.4572 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 23.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:27,938] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7721 - accuracy: 0.0000e+00\n",
      "Epoch 00005: val_loss improved from 23.08996 to 21.48997, saving model to model_checkpoints/particle_net_lite_model.005.h5\n",
      "5/5 [==============================] - 3s 609ms/step - loss: 0.7721 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 21.4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:31,867] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.9215 - accuracy: 0.0000e+00\n",
      "Epoch 00006: val_loss improved from 21.48997 to 20.68785, saving model to model_checkpoints/particle_net_lite_model.006.h5\n",
      "5/5 [==============================] - 3s 610ms/step - loss: 0.9215 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 20.6879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:35,830] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8693 - accuracy: 0.0000e+00\n",
      "Epoch 00007: val_loss did not improve from 20.68785\n",
      "5/5 [==============================] - 3s 616ms/step - loss: 0.8693 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 20.7203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:39,815] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3176 - accuracy: 0.0000e+00\n",
      "Epoch 00008: val_loss did not improve from 20.68785\n",
      "5/5 [==============================] - 3s 613ms/step - loss: 0.3176 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 20.9537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:43,781] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2575 - accuracy: 0.0000e+00\n",
      "Epoch 00009: val_loss did not improve from 20.68785\n",
      "5/5 [==============================] - 3s 646ms/step - loss: 0.2575 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 20.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:47,918] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.0000e+00\n",
      "Epoch 00010: val_loss did not improve from 20.68785\n",
      "5/5 [==============================] - 3s 651ms/step - loss: 0.2831 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 20.7681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:52,149] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.0000e+00\n",
      "Epoch 00011: val_loss improved from 20.68785 to 20.39607, saving model to model_checkpoints/particle_net_lite_model.011.h5\n",
      "5/5 [==============================] - 3s 664ms/step - loss: 0.1768 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 20.3961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:39:56,448] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.0000e+00\n",
      "Epoch 00012: val_loss improved from 20.39607 to 20.25451, saving model to model_checkpoints/particle_net_lite_model.012.h5\n",
      "5/5 [==============================] - 3s 626ms/step - loss: 0.1385 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 20.2545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:00,528] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.0000e+00\n",
      "Epoch 00013: val_loss improved from 20.25451 to 20.10238, saving model to model_checkpoints/particle_net_lite_model.013.h5\n",
      "5/5 [==============================] - 3s 623ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 20.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:04,557] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.0000e+00\n",
      "Epoch 00014: val_loss improved from 20.10238 to 19.93992, saving model to model_checkpoints/particle_net_lite_model.014.h5\n",
      "5/5 [==============================] - 3s 629ms/step - loss: 0.1327 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 19.9399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:08,602] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.0000e+00\n",
      "Epoch 00015: val_loss improved from 19.93992 to 19.76786, saving model to model_checkpoints/particle_net_lite_model.015.h5\n",
      "5/5 [==============================] - 3s 620ms/step - loss: 0.1340 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 19.7679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:12,613] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.0000e+00\n",
      "Epoch 00016: val_loss improved from 19.76786 to 19.58534, saving model to model_checkpoints/particle_net_lite_model.016.h5\n",
      "5/5 [==============================] - 3s 618ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 19.5853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:16,588] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.0000e+00\n",
      "Epoch 00017: val_loss improved from 19.58534 to 19.39331, saving model to model_checkpoints/particle_net_lite_model.017.h5\n",
      "5/5 [==============================] - 3s 631ms/step - loss: 0.1371 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 19.3933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:20,660] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.0000e+00\n",
      "Epoch 00018: val_loss improved from 19.39331 to 19.18932, saving model to model_checkpoints/particle_net_lite_model.018.h5\n",
      "5/5 [==============================] - 3s 620ms/step - loss: 0.1319 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 19.1893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:24,663] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.0000e+00\n",
      "Epoch 00019: val_loss improved from 19.18932 to 18.97365, saving model to model_checkpoints/particle_net_lite_model.019.h5\n",
      "5/5 [==============================] - 3s 623ms/step - loss: 0.1327 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 18.9737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:28,692] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.0000e+00\n",
      "Epoch 00020: val_loss improved from 18.97365 to 18.74618, saving model to model_checkpoints/particle_net_lite_model.020.h5\n",
      "5/5 [==============================] - 3s 621ms/step - loss: 0.1333 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 18.7462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:32,699] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.0000e+00\n",
      "Epoch 00021: val_loss improved from 18.74618 to 18.50646, saving model to model_checkpoints/particle_net_lite_model.021.h5\n",
      "5/5 [==============================] - 3s 651ms/step - loss: 0.1330 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 18.5065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:36,886] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.0000e+00\n",
      "Epoch 00022: val_loss improved from 18.50646 to 18.25844, saving model to model_checkpoints/particle_net_lite_model.022.h5\n",
      "5/5 [==============================] - 3s 648ms/step - loss: 0.1288 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 18.2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:41,079] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.0000e+00\n",
      "Epoch 00023: val_loss improved from 18.25844 to 18.00086, saving model to model_checkpoints/particle_net_lite_model.023.h5\n",
      "5/5 [==============================] - 4s 711ms/step - loss: 0.1315 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 18.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:45,600] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.0000e+00\n",
      "Epoch 00024: val_loss improved from 18.00086 to 17.73530, saving model to model_checkpoints/particle_net_lite_model.024.h5\n",
      "5/5 [==============================] - 4s 707ms/step - loss: 0.1296 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 17.7353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:50,181] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.0000e+00\n",
      "Epoch 00025: val_loss improved from 17.73530 to 17.45712, saving model to model_checkpoints/particle_net_lite_model.025.h5\n",
      "5/5 [==============================] - 3s 655ms/step - loss: 0.1301 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 17.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:54,427] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.0000e+00\n",
      "Epoch 00026: val_loss improved from 17.45712 to 17.17020, saving model to model_checkpoints/particle_net_lite_model.026.h5\n",
      "5/5 [==============================] - 3s 654ms/step - loss: 0.1250 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 17.1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:40:58,650] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.0000e+00\n",
      "Epoch 00027: val_loss improved from 17.17020 to 16.87692, saving model to model_checkpoints/particle_net_lite_model.027.h5\n",
      "5/5 [==============================] - 3s 649ms/step - loss: 0.1285 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 16.8769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:41:02,852] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.0000e+00\n",
      "Epoch 00028: val_loss improved from 16.87692 to 16.57355, saving model to model_checkpoints/particle_net_lite_model.028.h5\n",
      "5/5 [==============================] - 3s 656ms/step - loss: 0.1238 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 16.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:41:07,069] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.0000e+00\n",
      "Epoch 00029: val_loss improved from 16.57355 to 16.26581, saving model to model_checkpoints/particle_net_lite_model.029.h5\n",
      "5/5 [==============================] - 3s 651ms/step - loss: 0.1237 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 16.2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-04 10:41:11,272] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.0000e+00\n",
      "Epoch 00030: val_loss improved from 16.26581 to 15.95359, saving model to model_checkpoints/particle_net_lite_model.030.h5\n",
      "5/5 [==============================] - 3s 654ms/step - loss: 0.1255 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 15.9536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe8af5c7748>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shuffle()\n",
    "model.fit(train_dataset.X, train_dataset.y,\n",
    "          batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "          epochs=30, # --- train only for 1 epoch here for demonstration ---\n",
    "          validation_data=(val_dataset.X, val_dataset.y),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2355587]\n",
      "[2.263892]\n",
      "[1.9904692]\n",
      "[2.0716598]\n",
      "[2.1739566]\n",
      "[2.1478882]\n",
      "[2.0731783]\n",
      "[2.1058273]\n",
      "[2.1574616]\n",
      "[2.061681]\n",
      "[2.2142441]\n",
      "[2.153094]\n",
      "[2.0303738]\n",
      "[2.0304387]\n",
      "[2.1040561]\n",
      "[2.1510427]\n",
      "[2.1811533]\n",
      "[2.0896368]\n",
      "[2.156884]\n",
      "[2.0285914]\n",
      "[2.0999713]\n",
      "[2.1493244]\n",
      "[2.1204877]\n",
      "[2.005537]\n",
      "[2.1498725]\n",
      "[2.2014647]\n",
      "[2.1142707]\n",
      "[2.141198]\n",
      "[2.2180314]\n",
      "[2.1213305]\n",
      "[2.1032257]\n",
      "[2.0453799]\n",
      "[2.101873]\n",
      "[2.1368816]\n",
      "[2.1217015]\n",
      "[2.2747025]\n",
      "[2.1699953]\n",
      "[2.1023476]\n",
      "[2.1776586]\n",
      "[2.0868165]\n",
      "[2.1228402]\n",
      "[2.0104]\n",
      "[2.169025]\n",
      "[2.2086189]\n",
      "[2.0947545]\n",
      "[2.1251929]\n",
      "[2.0240119]\n",
      "[2.205694]\n",
      "[2.1174688]\n",
      "[2.2067692]\n",
      "[2.0292854]\n",
      "[2.1025047]\n",
      "[2.106222]\n",
      "[2.0701768]\n",
      "[2.1069267]\n",
      "[2.2311242]\n",
      "[2.2329934]\n",
      "[2.1579502]\n",
      "[2.1621525]\n",
      "[2.1256273]\n",
      "[1.9916127]\n",
      "[1.989718]\n",
      "[2.0969675]\n",
      "[2.0354187]\n",
      "[2.061754]\n",
      "[2.016888]\n",
      "[2.2054718]\n",
      "[2.1494567]\n",
      "[2.0751963]\n",
      "[2.2164342]\n",
      "[2.0571394]\n",
      "[2.092072]\n",
      "[2.1033242]\n",
      "[2.117317]\n",
      "[2.2183459]\n",
      "[2.1128912]\n",
      "[2.1693864]\n",
      "[2.2150085]\n",
      "[2.2009718]\n",
      "[2.1880624]\n",
      "[2.216729]\n",
      "[2.1379833]\n",
      "[2.075752]\n",
      "[2.1628091]\n",
      "[2.144723]\n",
      "[2.1720572]\n",
      "[2.2776003]\n",
      "[2.1029267]\n",
      "[2.1034646]\n",
      "[2.1134994]\n",
      "[2.1059737]\n",
      "[2.0807273]\n",
      "[2.185872]\n",
      "[2.1169727]\n",
      "[2.1107218]\n",
      "[2.2119005]\n",
      "[2.005784]\n",
      "[2.2083778]\n",
      "[2.2274404]\n",
      "[2.1237113]\n",
      "[2.129395]\n",
      "[1.955222]\n",
      "[2.0341394]\n",
      "[2.1088274]\n",
      "[2.112131]\n",
      "[2.2742312]\n",
      "[2.0360022]\n",
      "[2.0989947]\n",
      "[2.1927383]\n",
      "[2.084887]\n",
      "[2.1875594]\n",
      "[2.1382473]\n",
      "[2.1479616]\n",
      "[2.2500255]\n",
      "[2.153761]\n",
      "[2.0686224]\n",
      "[2.1081717]\n",
      "[1.9597995]\n",
      "[2.1377409]\n",
      "[2.1132658]\n",
      "[2.1225016]\n",
      "[2.0967782]\n",
      "[2.1214364]\n",
      "[2.161442]\n",
      "[2.1512072]\n",
      "[2.0382416]\n",
      "[2.112222]\n",
      "[2.0939364]\n",
      "[2.1533592]\n",
      "[2.199945]\n",
      "[2.1236212]\n",
      "[2.1545708]\n",
      "[2.0534859]\n",
      "[2.0833645]\n",
      "[2.1494803]\n",
      "[2.117443]\n",
      "[2.1972768]\n",
      "[1.9900632]\n",
      "[2.2002013]\n",
      "[2.2295513]\n",
      "[2.0613244]\n",
      "[2.126275]\n",
      "[2.1606982]\n",
      "[2.115039]\n",
      "[2.1205597]\n",
      "[2.1317651]\n",
      "[2.1016977]\n",
      "[2.1348653]\n",
      "[2.1371233]\n",
      "[2.142481]\n",
      "[2.1113281]\n",
      "[2.192223]\n",
      "[2.1573586]\n",
      "[2.097027]\n",
      "[2.2365124]\n",
      "[2.0821784]\n",
      "[2.1572661]\n",
      "[2.0785747]\n",
      "[2.061601]\n",
      "[2.2441175]\n",
      "[2.0509427]\n",
      "[2.1117527]\n",
      "[2.1003494]\n",
      "[2.1470678]\n",
      "[2.1096988]\n",
      "[2.1142547]\n",
      "[2.114847]\n",
      "[2.0704534]\n",
      "[2.0969312]\n",
      "[2.111769]\n",
      "[2.142137]\n",
      "[2.0823045]\n",
      "[2.1271322]\n",
      "[2.1773403]\n",
      "[2.2369845]\n",
      "[2.2275422]\n",
      "[2.3142881]\n",
      "[2.0855095]\n",
      "[2.1158214]\n",
      "[2.1092436]\n",
      "[2.117022]\n",
      "[2.1358767]\n",
      "[2.2376075]\n",
      "[2.0598614]\n",
      "[2.1139715]\n",
      "[2.0748992]\n",
      "[2.175321]\n",
      "[2.1483839]\n",
      "[2.2254431]\n",
      "[2.20962]\n",
      "[2.1601403]\n",
      "[2.1269207]\n",
      "[2.1324856]\n",
      "[2.2005365]\n",
      "[2.1179354]\n",
      "[2.1539104]\n",
      "[2.1349664]\n",
      "[2.0775437]\n",
      "[2.2215745]\n",
      "[2.080848]\n",
      "[2.0735555]\n",
      "[2.2701356]\n",
      "[2.1570928]\n",
      "[2.2401907]\n",
      "[2.1326334]\n",
      "[2.1859686]\n",
      "[2.0875952]\n",
      "[2.1109421]\n",
      "[2.0916924]\n",
      "[2.2311296]\n",
      "[2.0347645]\n",
      "[2.1439652]\n",
      "[2.2261834]\n",
      "[2.1254385]\n",
      "[2.1004403]\n",
      "[2.1136596]\n",
      "[2.0872793]\n",
      "[2.1758735]\n",
      "[2.2187467]\n",
      "[2.1693747]\n",
      "[2.205584]\n",
      "[2.1964042]\n",
      "[2.0612082]\n",
      "[2.0837858]\n",
      "[2.1635773]\n",
      "[2.1680303]\n",
      "[2.1017964]\n",
      "[2.1597922]\n",
      "[2.2003796]\n",
      "[2.1714115]\n",
      "[2.0904696]\n",
      "[2.0883691]\n",
      "[2.1631944]\n",
      "[2.1543682]\n",
      "[2.1256158]\n",
      "[2.163149]\n",
      "[2.072084]\n",
      "[2.0380025]\n",
      "[2.122564]\n",
      "[2.181023]\n",
      "[2.0863292]\n",
      "[2.184759]\n",
      "[2.1201217]\n",
      "[2.0773132]\n",
      "[2.1602464]\n",
      "[2.2688851]\n",
      "[2.0772874]\n",
      "[2.105988]\n",
      "[2.1486473]\n",
      "[2.1614273]\n",
      "[2.0882614]\n",
      "[2.193692]\n",
      "[2.0243464]\n",
      "[1.9522401]\n",
      "[2.1067512]\n",
      "[2.0417318]\n",
      "[2.2449543]\n",
      "[2.1089044]\n",
      "[2.1455634]\n",
      "[2.1029341]\n",
      "[2.2260568]\n",
      "[2.0917733]\n",
      "[2.0515125]\n",
      "[2.23877]\n",
      "[1.946672]\n",
      "[2.1665483]\n",
      "[2.109276]\n",
      "[2.097317]\n",
      "[2.130092]\n",
      "[2.0938065]\n",
      "[2.1012757]\n",
      "[2.1144686]\n",
      "[2.199462]\n",
      "[2.051501]\n",
      "[2.265368]\n",
      "[2.0898485]\n",
      "[2.0925066]\n",
      "[2.086965]\n",
      "[2.1538012]\n",
      "[2.180099]\n",
      "[2.1704412]\n",
      "[2.0909176]\n",
      "[2.142929]\n",
      "[2.104524]\n",
      "[2.067407]\n",
      "[2.1720064]\n",
      "[2.2576764]\n",
      "[2.0831423]\n",
      "[2.079647]\n",
      "[2.0593345]\n",
      "[2.110934]\n",
      "[2.0799208]\n",
      "[2.2997682]\n",
      "[2.1977637]\n",
      "[2.1406548]\n",
      "[2.3165786]\n",
      "[2.108526]\n",
      "[2.0854821]\n",
      "[2.0940716]\n",
      "[2.1417341]\n",
      "[2.17514]\n",
      "[2.133293]\n",
      "[2.2205007]\n",
      "[2.1394393]\n",
      "[2.0810032]\n",
      "[1.9862504]\n",
      "[2.117437]\n",
      "[2.2662783]\n",
      "[2.1874602]\n",
      "[2.2126164]\n",
      "[2.0950391]\n",
      "[2.1042666]\n",
      "[2.090808]\n",
      "[2.0351708]\n",
      "[2.1252966]\n",
      "[2.1319525]\n",
      "[2.1327512]\n",
      "[2.104468]\n",
      "[2.1377218]\n",
      "[2.0458884]\n",
      "[2.1752615]\n",
      "[2.025045]\n",
      "[2.250113]\n",
      "[2.096564]\n",
      "[2.1159778]\n",
      "[2.0353725]\n",
      "[2.2010806]\n",
      "[2.1293633]\n",
      "[2.0707061]\n",
      "[2.0472143]\n",
      "[2.0935948]\n",
      "[2.0099134]\n",
      "[2.0968225]\n",
      "[2.150732]\n",
      "[2.1282861]\n",
      "[2.2821324]\n",
      "[2.1595411]\n",
      "[2.2110708]\n",
      "[2.225796]\n",
      "[2.0834835]\n",
      "[2.1089442]\n",
      "[2.059545]\n",
      "[2.0825777]\n",
      "[2.0892355]\n",
      "[2.0879567]\n",
      "[2.152316]\n",
      "[2.1527088]\n",
      "[2.2139692]\n",
      "[2.0332003]\n",
      "[2.1163487]\n",
      "[2.1924956]\n",
      "[2.2896624]\n",
      "[2.0833864]\n",
      "[2.0498364]\n",
      "[2.198468]\n",
      "[2.1356728]\n",
      "[2.1493914]\n",
      "[2.0775435]\n",
      "[2.0927517]\n",
      "[2.1479475]\n",
      "[2.0498374]\n",
      "[2.13794]\n",
      "[2.1053379]\n",
      "[2.121108]\n",
      "[2.102252]\n",
      "[2.051032]\n",
      "[2.0950673]\n",
      "[2.175097]\n",
      "[2.1965902]\n",
      "[2.0670564]\n",
      "[2.116106]\n",
      "[2.143814]\n",
      "[2.0892127]\n",
      "[2.1190104]\n",
      "[2.1459057]\n",
      "[2.248352]\n",
      "[2.2508664]\n",
      "[2.1153448]\n",
      "[2.1196656]\n",
      "[2.1296816]\n",
      "[2.2393534]\n",
      "[2.071029]\n",
      "[2.1956577]\n",
      "[2.1700761]\n",
      "[2.0809128]\n",
      "[2.048673]\n",
      "[2.13249]\n",
      "[2.0989852]\n",
      "[2.1806698]\n",
      "[2.0363955]\n",
      "[2.2428248]\n",
      "[2.035532]\n",
      "[2.1861675]\n",
      "[2.0516663]\n",
      "[2.1775796]\n",
      "[2.1060462]\n",
      "[2.1434453]\n",
      "[2.2780008]\n",
      "[2.1301625]\n",
      "[2.1041808]\n",
      "[2.1075425]\n",
      "[2.092551]\n",
      "[2.0742316]\n",
      "[2.0331001]\n",
      "[2.150111]\n",
      "[2.0804431]\n",
      "[2.1703498]\n",
      "[2.223369]\n",
      "[2.062641]\n",
      "[2.1948507]\n",
      "[2.14759]\n",
      "[2.1198494]\n",
      "[2.119571]\n",
      "[2.221123]\n",
      "[2.1442351]\n",
      "[1.99386]\n",
      "[2.1899357]\n",
      "[2.2418885]\n",
      "[2.0740101]\n",
      "[2.0897753]\n",
      "[2.2000074]\n",
      "[2.1001303]\n",
      "[2.1123066]\n",
      "[2.1046531]\n",
      "[2.1412754]\n",
      "[2.0988019]\n",
      "[2.185312]\n",
      "[2.0265691]\n",
      "[2.1032417]\n",
      "[2.193689]\n",
      "[2.060941]\n",
      "[2.105186]\n",
      "[2.149513]\n",
      "[2.0613136]\n",
      "[2.0936882]\n",
      "[2.2069488]\n",
      "[2.1562498]\n",
      "[2.0994704]\n",
      "[2.103364]\n",
      "[2.166813]\n",
      "[2.128059]\n",
      "[2.1135314]\n",
      "[2.0932934]\n",
      "[2.1215327]\n",
      "[2.1264083]\n",
      "[2.1728241]\n",
      "[2.118114]\n",
      "[2.0820167]\n",
      "[2.161938]\n",
      "[2.1333084]\n",
      "[2.0985668]\n",
      "[2.208534]\n",
      "[2.109864]\n",
      "[2.1286204]\n",
      "[2.2118247]\n",
      "[2.0335197]\n",
      "[2.14945]\n",
      "[1.9938734]\n",
      "[2.1963146]\n",
      "[2.1484358]\n",
      "[2.1559446]\n",
      "[2.0797968]\n",
      "[2.1501987]\n",
      "[2.152288]\n",
      "[2.1488645]\n",
      "[2.0760834]\n",
      "[2.1285]\n",
      "[2.1914473]\n",
      "[2.1099107]\n",
      "[2.1234043]\n",
      "[2.127811]\n",
      "[2.1520646]\n",
      "[2.1121156]\n",
      "[2.1842203]\n",
      "[2.1740808]\n",
      "[2.187704]\n",
      "[2.191219]\n",
      "[2.145926]\n",
      "[2.0270045]\n",
      "[2.085098]\n",
      "[2.1016948]\n",
      "[2.2111986]\n",
      "[2.0805497]\n",
      "[2.0860875]\n",
      "[2.1131647]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_dataset.X)\n",
    "for prediction in predictions:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
