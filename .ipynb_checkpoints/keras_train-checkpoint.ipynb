{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "import uproot_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_arrays(a, keys, axis=-1):\n",
    "    flat_arr = np.stack([a[k].flatten() for k in keys], axis=axis)\n",
    "    return awkward.JaggedArray.fromcounts(a[keys[0]].counts, flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(a, maxlen, value=0., dtype='float32'):\n",
    "    x = (np.ones((len(a), maxlen)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(a):\n",
    "        if not len(s):\n",
    "            continue\n",
    "        trunc = s[:maxlen].astype(dtype)\n",
    "        x[idx, :len(trunc)] = trunc\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##and Professor suggests that we could use mass, classifacation for later application\n",
    "def SetAKArr(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    px_lists = []\n",
    "    px_ls = []\n",
    "    py_lists = []\n",
    "    py_ls = []\n",
    "    pz_lists = []\n",
    "    pz_ls = []\n",
    "    e_lists = []\n",
    "    e_ls = []\n",
    "    mass_lists = []\n",
    "    mass_ls = []\n",
    "    _label1 = []\n",
    "    _label2 = []\n",
    "    for line in lines:\n",
    "        if line.startswith('E'):\n",
    "            exp_inf = line.split()\n",
    "            _label1.append(int(exp_inf[1]))\n",
    "            _label2.append(1-int(exp_inf[1]))\n",
    "            if px_ls:\n",
    "                px_lists.append(px_ls)\n",
    "            ##clear the data in px list\n",
    "#             print(px_ls)\n",
    "            if py_ls:\n",
    "                py_lists.append(py_ls)\n",
    "            if pz_ls:\n",
    "                pz_lists.append(pz_ls)\n",
    "            if e_ls:\n",
    "                e_lists.append(e_ls)\n",
    "            if mass_ls:\n",
    "                mass_lists.append(mass_ls)\n",
    "            px_ls = []\n",
    "            py_ls = []\n",
    "            pz_ls = []\n",
    "            e_ls = []\n",
    "            mass_ls = []\n",
    "        else:\n",
    "            par = line.split()\n",
    "            px_ls.append(float(par[1]))\n",
    "            py_ls.append(float(par[2]))\n",
    "            pz_ls.append(float(par[3]))\n",
    "            e_ls.append(float(par[4]))\n",
    "            mass_ls.append(float(par[5]))\n",
    "            \n",
    "#     print(_label)\n",
    "    px = ak.JaggedArray.fromiter(px_lists)\n",
    "    py = ak.JaggedArray.fromiter(py_lists)\n",
    "    pz = ak.JaggedArray.fromiter(pz_lists)\n",
    "    energy = ak.JaggedArray.fromiter(e_lists)\n",
    "    mass = ak.JaggedArray.fromiter(mass_lists)\n",
    "    p4 = uproot_methods.TLorentzVectorArray.from_cartesian(px, py, pz, energy)\n",
    "    ##Create an Order Dic\n",
    "    from collections import OrderedDict\n",
    "    v = OrderedDict()\n",
    "    v['part_px'] = px\n",
    "    v['part_py'] = py\n",
    "    v['part_pz'] = pz\n",
    "    v['part_energy'] = energy\n",
    "    v['part_mass'] = mass\n",
    "#     ls1 = [1,2,3,4]\n",
    "#     ls2 = [5,6,7,8]\n",
    "    v['label'] = np.stack((_label1, _label2), axis=-1)\n",
    "#     print(v['label'])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset2(object):\n",
    "    def __init__(self, filepath, feature_dict = {}, label = 'E', pad_len=100, data_format='channel_first'):\n",
    "        self.filepath = filepath\n",
    "        self.feature_dict = feature_dict\n",
    "        if len(feature_dict) == 0:\n",
    "            feature_dict['points'] = ['part_px','part_py','part_pz']\n",
    "            feature_dict['features'] = ['part_energy', 'part_mass']\n",
    "            feature_dict['mask'] = ['part_energy']\n",
    "        ##currently we use 'E' for experiments\n",
    "        self.label = label\n",
    "        self.pad_len = pad_len\n",
    "        assert data_format in ('channel_first', 'channel_last')\n",
    "        self.stack_axis = 1 if data_format=='channel_first' else -1\n",
    "        self._values = {}\n",
    "        self._label = None\n",
    "        self._load()\n",
    "        \n",
    "    def _load(self):\n",
    "        logging.info('Start loading file %s' % self.filepath)\n",
    "        counts = None\n",
    "        a = SetAKArr(self.filepath)\n",
    "        for k in self.feature_dict:\n",
    "                cols = self.feature_dict[k]\n",
    "                if not isinstance(cols, (list, tuple)):\n",
    "                    cols = [cols]\n",
    "                arrs = []\n",
    "                for col in cols:\n",
    "                    arrs.append(pad_array(a[col], self.pad_len))\n",
    "                    ##check the dimesion of a[col], and it should be array.\n",
    "                self._values[k] = np.stack(arrs, axis=self.stack_axis)\n",
    "        logging.info('Finished loading file %s' % self.filepath)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key==self.label:\n",
    "            return self._label\n",
    "        else:\n",
    "            return self._values[key]\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._values\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._label\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        shuffle_indices = np.arange(self.__len__())\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        for k in self._values:\n",
    "            self._values[k] = self._values[k][shuffle_indices]\n",
    "        self._label = self._label[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-03 16:30:36,075] INFO: Start loading file train.txt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-afb6613df0f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channel_last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channel_last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d9405e75c5d1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, feature_dict, label, pad_len, data_format)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d9405e75c5d1>\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start loading file %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSetAKArr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0f9b206036a2>\u001b[0m in \u001b[0;36mSetAKArr\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#     print(_label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJaggedArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJaggedArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mpz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJaggedArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpz_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/awkward/array/jagged.py\u001b[0m in \u001b[0;36mfromiter\u001b[0;34m(cls, iterable)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJaggedArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mawkwardlib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/awkward/generate.py\u001b[0m in \u001b[0;36mfromiter\u001b[0;34m(iterable, awkwardlib, **options)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mfillable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfillable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfillable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/awkward/generate.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self, **options)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawkwardlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJaggedArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromoffsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTableFillable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFillable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/awkward/array/jagged.py\u001b[0m in \u001b[0;36mfromoffsets\u001b[0;34m(cls, offsets, content)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfromoffsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util_toarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINDEXTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/awkward/array/base.py\u001b[0m in \u001b[0;36m_util_toarray\u001b[0;34m(cls, value, defaultdtype, passthrough)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaultdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'list'"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset2('train.txt', data_format='channel_last')\n",
    "val_dataset = Dataset2('val.txt', data_format='channel_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/htk/miniforge3/envs/tensorflow/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZNK6google8protobuf10TextFormat17FieldValuePrinter9PrintBoolEb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7bc372f56b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_particle_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_particle_net_lite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/core/framework/graph_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdescriptor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_descriptor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreflection\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_reflection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/google/protobuf/descriptor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mbinascii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0m_USE_C_DESCRIPTORS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_USE_C_DESCRIPTORS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/htk/miniforge3/envs/tensorflow/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZNK6google8protobuf10TextFormat17FieldValuePrinter9PrintBoolEb"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tf_keras_model import get_particle_net, get_particle_net_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-4cf1e7cb4994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'particle_net_lite'\u001b[0m \u001b[0;31m# choose between 'particle_net' and 'particle_net_lite'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'lite'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_particle_net_lite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model_type = 'particle_net_lite' # choose between 'particle_net' and 'particle_net_lite'\n",
    "num_classes = train_dataset.y.shape[1]\n",
    "input_shapes = {k:train_dataset[k].shape[1:] for k in train_dataset.X}\n",
    "if 'lite' in model_type:\n",
    "    model = get_particle_net_lite(num_classes, input_shapes)\n",
    "else:\n",
    "    model = get_particle_net(num_classes, input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 1024 if 'lite' in model_type else 384\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 10:\n",
    "        lr *= 0.1\n",
    "    elif epoch > 20:\n",
    "        lr *= 0.01\n",
    "    logging.info('Learning rate: %f'%lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-27 13:36:50,708] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ParticleNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mask (InputLayer)               [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.not_equal (TFOpLambda)  (None, 100, 1)       0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 100, 1)       0           tf.math.not_equal[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.equal (TFOpLambda)      (None, 100, 1)       0           tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_1 (TFOpLambda)          (None, 100, 1)       0           tf.math.equal[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 100, 1)       0           tf.cast_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "points (InputLayer)             [(None, 100, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add (TFOpLambda)        (None, 100, 2)       0           tf.math.multiply[0][0]           \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 100, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (None, 2, 100)       0           tf.math.add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims (TFOpLambda)     (None, 100, 1, 4)    0           features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 100, 2)       0           tf.math.add[0][0]                \n",
      "                                                                 tf.math.add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul (TFOpLambda)   (None, 100, 100)     0           tf.math.add[0][0]                \n",
      "                                                                 tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 100, 2)       0           tf.math.add[0][0]                \n",
      "                                                                 tf.math.add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_fts_bn (BatchNormal (None, 100, 1, 4)    16          tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 100, 1)       0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 100, 100)     0           tf.linalg.matmul[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 100, 1)       0           tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 100, 4)       0           ParticleNet_fts_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 100, 100)     0           tf.math.reduce_sum[0][0]         \n",
      "                                                                 tf.math.multiply_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_1 (TFOpL (None, 1, 100)       0           tf.math.reduce_sum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape (TFOpLambda) (3,)                 0           tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 100, 100)     0           tf.math.subtract[0][0]           \n",
      "                                                                 tf.compat.v1.transpose_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli ()                   0           tf.compat.v1.shape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.negative (TFOpLambda)   (None, 100, 100)     0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.range (TFOpLambda)           (None,)              0           tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.top_k (TFOpLambda)      TopKV2(values=(None, 0           tf.math.negative[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None, 1, 1, 1)      0           tf.range[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 100, 7)       0           tf.math.top_k[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile (TFOpLambda)            (None, 100, 7, 1)    0           tf.reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_1 (TFOpLambda)   (None, 100, 7, 1)    0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_2 (TFOpLambda)   (None, 100, 1, 4)    0           tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 100, 7, 2)    0           tf.tile[0][0]                    \n",
      "                                                                 tf.expand_dims_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile_1 (TFOpLambda)          (None, 100, 7, 4)    0           tf.expand_dims_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.gather_nd (TFOpLam (None, 100, 7, 4)    0           tf.compat.v1.squeeze[0][0]       \n",
      "                                                                 tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 100, 7, 4)    0           tf.compat.v1.gather_nd[0][0]     \n",
      "                                                                 tf.tile_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (None, 100, 7, 8)    0           tf.tile_1[0][0]                  \n",
      "                                                                 tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv0 (Co (None, 100, 7, 32)   256         tf.concat_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn0 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act0 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv1 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn1 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act1 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_3 (TFOpLambda)   (None, 100, 1, 4)    0           tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv2 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_conv ( (None, 100, 1, 32)   128         tf.expand_dims_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn2 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_bn (Ba (None, 100, 1, 32)   128         ParticleNet_EdgeConv0_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act2 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_1 (TFOpLam (None, 100, 32)      0           ParticleNet_EdgeConv0_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 100, 32)      0           ParticleNet_EdgeConv0_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 100, 32)      0           tf.compat.v1.squeeze_1[0][0]     \n",
      "                                                                 tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_act (A (None, 100, 32)      0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_1 (TFOpLambda)      (None, 100, 32)      0           tf.math.multiply[0][0]           \n",
      "                                                                 ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_2 (TFOpL (None, 32, 100)      0           tf.math.add_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_4 (TFOpLambda) (None, 100, 32)      0           tf.math.add_1[0][0]              \n",
      "                                                                 tf.math.add_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_1 (TFOpLambda) (None, 100, 100)     0           tf.math.add_1[0][0]              \n",
      "                                                                 tf.compat.v1.transpose_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_5 (TFOpLambda) (None, 100, 32)      0           tf.math.add_1[0][0]              \n",
      "                                                                 tf.math.add_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_2 (TFOpLambd (None, 100, 1)       0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_6 (TFOpLambda) (None, 100, 100)     0           tf.linalg.matmul_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_3 (TFOpLambd (None, 100, 1)       0           tf.math.multiply_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_2 (TFOpLambda) (None, 100, 100)     0           tf.math.reduce_sum_2[0][0]       \n",
      "                                                                 tf.math.multiply_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_3 (TFOpL (None, 1, 100)       0           tf.math.reduce_sum_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_1 (TFOpLambd (3,)                 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 100, 100)     0           tf.math.subtract_2[0][0]         \n",
      "                                                                 tf.compat.v1.transpose_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.negative_1 (TFOpLambda) (None, 100, 100)     0           tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_1 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.top_k_1 (TFOpLambda)    TopKV2(values=(None, 0           tf.math.negative_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_1 (TFOpLambda)       (None, 1, 1, 1)      0           tf.range_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 100, 7)       0           tf.math.top_k_1[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile_2 (TFOpLambda)          (None, 100, 7, 1)    0           tf.reshape_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_4 (TFOpLambda)   (None, 100, 7, 1)    0           tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_5 (TFOpLambda)   (None, 100, 1, 32)   0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_2 (TFOpLambda)        (None, 100, 7, 2)    0           tf.tile_2[0][0]                  \n",
      "                                                                 tf.expand_dims_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile_3 (TFOpLambda)          (None, 100, 7, 32)   0           tf.expand_dims_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.gather_nd_1 (TFOpL (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "                                                                 tf.concat_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_3 (TFOpLambda) (None, 100, 7, 32)   0           tf.compat.v1.gather_nd_1[0][0]   \n",
      "                                                                 tf.tile_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_3 (TFOpLambda)        (None, 100, 7, 64)   0           tf.tile_3[0][0]                  \n",
      "                                                                 tf.math.subtract_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv0 (Co (None, 100, 7, 64)   4096        tf.concat_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn0 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act0 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv1 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn1 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act1 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_6 (TFOpLambda)   (None, 100, 1, 32)   0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv2 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_conv ( (None, 100, 1, 64)   2048        tf.expand_dims_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn2 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_bn (Ba (None, 100, 1, 64)   256         ParticleNet_EdgeConv1_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act2 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_2 (TFOpLam (None, 100, 64)      0           ParticleNet_EdgeConv1_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 100, 64)      0           ParticleNet_EdgeConv1_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 100, 64)      0           tf.compat.v1.squeeze_2[0][0]     \n",
      "                                                                 tf.math.reduce_mean_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_act (A (None, 100, 64)      0           tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_7 (TFOpLambda) (None, 100, 64)      0           ParticleNet_EdgeConv1_sc_act[0][0\n",
      "                                                                 tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_2 (TFOpLamb (None, 64)           0           tf.math.multiply_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          8320        tf.math.reduce_mean_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,898\n",
      "Trainable params: 26,122\n",
      "Non-trainable params: 776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "import os\n",
    "save_dir = 'model_checkpoints'\n",
    "model_name = '%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "progress_bar = keras.callbacks.ProgbarLogger()\n",
    "callbacks = [checkpoint, lr_scheduler, progress_bar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 13:36:58.829210: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1937600000 exceeds 10% of free system memory.\n",
      "2023-11-27 13:36:59.744611: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-11-27 13:36:59.744872: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2688000000 Hz\n",
      "[2023-11-27 13:36:59,767] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/Unknown - 1617s 0s/sample - loss: 0.2187 - accuracy: 0.9116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-27 14:05:37,527] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1183/1183 [==============================] - 1718s 1s/sample - loss: 0.2187 - accuracy: 0.9116 - val_loss: 0.1918 - val_accuracy: 0.9235 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb3f6a6a190>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shuffle()\n",
    "model.fit(train_dataset.X, train_dataset.y,\n",
    "          batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "          epochs=1, # --- train only for 1 epoch here for demonstration ---\n",
    "          validation_data=(val_dataset.X, val_dataset.y),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
