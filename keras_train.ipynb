{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "import uproot_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_arrays(a, keys, axis=-1):\n",
    "    flat_arr = np.stack([a[k].flatten() for k in keys], axis=axis)\n",
    "    return awkward.JaggedArray.fromcounts(a[keys[0]].counts, flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(a, maxlen, value=0., dtype='float32'):\n",
    "    x = (np.ones((len(a), maxlen)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(a):\n",
    "        if not len(s):\n",
    "            continue\n",
    "        trunc = s[:maxlen].astype(dtype)\n",
    "        x[idx, :len(trunc)] = trunc\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##and Professor suggests that we could use mass, classifacation for later application\n",
    "def SetAKArr(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    n_particles_ls = []\n",
    "    px_ls = []\n",
    "    py_ls = []\n",
    "    pz_ls = []\n",
    "    energy_ls = []\n",
    "    mass_ls = []\n",
    "    _label1 = []\n",
    "    _label2 = []\n",
    "    n = 0\n",
    "    for line in lines:\n",
    "        if line.startswith('E'):\n",
    "            if not n == 0:\n",
    "                n_particles_ls.append(n)\n",
    "                n = 0\n",
    "            exp_inf = line.split()\n",
    "            _label1.append(int(exp_inf[1]))\n",
    "            _label2.append(1-int(exp_inf[1]))\n",
    "        else:\n",
    "            par = line.split()\n",
    "            ##particle +1\n",
    "            n = n + 1\n",
    "            px_ls.append(float(par[1]))\n",
    "            py_ls.append(float(par[2]))\n",
    "            pz_ls.append(float(par[3]))\n",
    "            energy_ls.append(float(par[4]))\n",
    "            mass_ls.append(float(par[5]))            \n",
    "    if not n == 0:\n",
    "        n_particles_ls.append(n)\n",
    "    px_arr = np.array(px_ls)\n",
    "    py_arr = np.array(py_ls)\n",
    "    pz_arr = np.array(pz_ls)\n",
    "    energy_arr = np.array(energy_ls)\n",
    "    mass_arr = np.array(mass_ls)\n",
    "    n_particles = np.array(n_particles_ls)\n",
    "\n",
    "#     print(n_particles)\n",
    "    px = ak.JaggedArray.fromcounts(n_particles, px_arr)\n",
    "    py = ak.JaggedArray.fromcounts(n_particles, py_arr)\n",
    "    pz = ak.JaggedArray.fromcounts(n_particles, pz_arr)\n",
    "    energy = ak.JaggedArray.fromcounts(n_particles, energy_arr)\n",
    "    mass = ak.JaggedArray.fromcounts(n_particles, mass_arr)\n",
    "    p4 = uproot_methods.TLorentzVectorArray.from_cartesian(px, py, pz, energy)\n",
    "    ##Create an Order Dic\n",
    "    from collections import OrderedDict\n",
    "    v = OrderedDict()\n",
    "    v['part_px'] = px\n",
    "#     print(px)\n",
    "    v['part_py'] = py\n",
    "    v['part_pz'] = pz\n",
    "    v['part_energy'] = energy\n",
    "    v['part_mass'] = mass\n",
    "#     ls1 = [1,2,3,4]\n",
    "#     ls2 = [5,6,7,8]\n",
    "    v['label'] = np.stack((_label1, _label2), axis=-1)\n",
    "    \n",
    "#     print(v['label'])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset2(object):\n",
    "    def __init__(self, filepath, feature_dict = {}, label = 'label', pad_len=100, data_format='channel_first'):\n",
    "        self.filepath = filepath\n",
    "        self.feature_dict = feature_dict\n",
    "        if len(feature_dict) == 0:\n",
    "            feature_dict['points'] = ['part_px','part_py','part_pz']\n",
    "            feature_dict['features'] = ['part_energy', 'part_mass']\n",
    "            feature_dict['mask'] = ['part_energy']\n",
    "        ##currently we use 'E' for experiments\n",
    "        self.label = label\n",
    "        self.pad_len = pad_len\n",
    "        assert data_format in ('channel_first', 'channel_last')\n",
    "        self.stack_axis = 1 if data_format=='channel_first' else -1\n",
    "        self._values = {}\n",
    "        self._label = None\n",
    "        self._load()\n",
    "        \n",
    "    def _load(self):\n",
    "        logging.info('Start loading file %s' % self.filepath)\n",
    "#         counts = None\n",
    "        a = SetAKArr(self.filepath)\n",
    "        self._label = a[self.label]\n",
    "        for k in self.feature_dict:\n",
    "                cols = self.feature_dict[k]\n",
    "                if not isinstance(cols, (list, tuple)):\n",
    "                    cols = [cols]\n",
    "                arrs = []\n",
    "                for col in cols:\n",
    "                    arrs.append(pad_array(a[col], self.pad_len))\n",
    "                    ##check the dimesion of a[col], and it should be array.\n",
    "                self._values[k] = np.stack(arrs, axis=self.stack_axis)\n",
    "        logging.info('Finished loading file %s' % self.filepath)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key==self.label:\n",
    "            return self._label\n",
    "        else:\n",
    "            return self._values[key]\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._values\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._label\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        shuffle_indices = np.arange(self.__len__())\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        for k in self._values:\n",
    "            self._values[k] = self._values[k][shuffle_indices]\n",
    "        self._label = self._label[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-04 21:57:18,776] INFO: Start loading file train.txt\n",
      "[2024-02-04 21:57:18,809] INFO: Finished loading file train.txt\n",
      "[2024-02-04 21:57:18,810] INFO: Start loading file val.txt\n",
      "[2024-02-04 21:57:18,820] INFO: Finished loading file val.txt\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset2('train.txt', data_format='channel_last')\n",
    "val_dataset = Dataset2('val.txt', data_format='channel_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tf_keras_model import get_particle_net, get_particle_net_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'particle_net_lite' # choose between 'particle_net' and 'particle_net_lite'\n",
    "num_classes = train_dataset.y.shape[1]\n",
    "input_shapes = {k:train_dataset[k].shape[1:] for k in train_dataset.X}\n",
    "if 'lite' in model_type:\n",
    "    model = get_particle_net_lite(num_classes, input_shapes)\n",
    "else:\n",
    "    model = get_particle_net(num_classes, input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 1024 if 'lite' in model_type else 384\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 10:\n",
    "        lr *= 0.1\n",
    "    elif epoch > 20:\n",
    "        lr *= 0.01\n",
    "    logging.info('Learning rate: %f'%lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-04 21:57:28,919] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ParticleNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mask (InputLayer)               [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_NotEqual_1 (TensorF [(None, 100, 1)]     0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_2 (TensorFlowO [(None, 100, 1)]     0           tf_op_layer_NotEqual_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal_1 (TensorFlow [(None, 100, 1)]     0           tf_op_layer_Cast_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_3 (TensorFlowO [(None, 100, 1)]     0           tf_op_layer_Equal_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_8 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Cast_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "points (InputLayer)             [(None, 100, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_2 (TensorFlowOp [(None, 100, 3)]     0           tf_op_layer_Mul_8[0][0]          \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 100, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_4 (Tensor [(None, 3, 100)]     0           tf_op_layer_Add_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_7 (Tenso [(None, 100, 1, 2)]  0           features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_9 (TensorFlowOp [(None, 100, 3)]     0           tf_op_layer_Add_2[0][0]          \n",
      "                                                                 tf_op_layer_Add_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_2 (Te [(None, 100, 100)]   0           tf_op_layer_Add_2[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_10 (TensorFlowO [(None, 100, 3)]     0           tf_op_layer_Add_2[0][0]          \n",
      "                                                                 tf_op_layer_Add_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_fts_bn (BatchNormal (None, 100, 1, 2)    8           tf_op_layer_ExpandDims_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_4 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_11 (TensorFlowO [(None, 100, 100)]   0           tf_op_layer_BatchMatMulV2_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_5 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_3 (TensorFl [(None, 100, 2)]     0           ParticleNet_fts_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_4 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sum_4[0][0]          \n",
      "                                                                 tf_op_layer_Mul_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_5 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(3,)]               0           tf_op_layer_Squeeze_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(None, 100, 100)]   0           tf_op_layer_Sub_4[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_AddV2_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_2 (TensorFlow [(None,)]            0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2_2 (TensorFlo [(None, 100, 8), (No 0           tf_op_layer_Neg_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 1, 1, 1)]    0           tf_op_layer_Range_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 100, 7)]     0           tf_op_layer_TopKV2_2[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_4 (TensorFlowO [(None, 100, 7, 1)]  0           tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_8 (Tenso [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_9 (Tenso [(None, 100, 1, 2)]  0           tf_op_layer_Squeeze_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_4 (TensorFlo [(None, 100, 7, 2)]  0           tf_op_layer_Tile_4[0][0]         \n",
      "                                                                 tf_op_layer_ExpandDims_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_5 (TensorFlowO [(None, 100, 7, 2)]  0           tf_op_layer_ExpandDims_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_2 (TensorF [(None, 100, 7, 2)]  0           tf_op_layer_Squeeze_3[0][0]      \n",
      "                                                                 tf_op_layer_concat_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_5 (TensorFlowOp [(None, 100, 7, 2)]  0           tf_op_layer_GatherNd_2[0][0]     \n",
      "                                                                 tf_op_layer_Tile_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_5 (TensorFlo [(None, 100, 7, 4)]  0           tf_op_layer_Tile_5[0][0]         \n",
      "                                                                 tf_op_layer_Sub_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv0 (Co (None, 100, 7, 32)   128         tf_op_layer_concat_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn0 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act0 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv1 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn1 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act1 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_10 (Tens [(None, 100, 1, 2)]  0           tf_op_layer_Squeeze_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv2 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_conv ( (None, 100, 1, 32)   64          tf_op_layer_ExpandDims_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn2 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_bn (Ba (None, 100, 1, 32)   128         ParticleNet_EdgeConv0_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act2 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_4 (TensorFl [(None, 100, 32)]    0           ParticleNet_EdgeConv0_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_3 (TensorFlowO [(None, 100, 32)]    0           ParticleNet_EdgeConv0_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorFlow [(None, 100, 32)]    0           tf_op_layer_Squeeze_4[0][0]      \n",
      "                                                                 tf_op_layer_Mean_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_act (A (None, 100, 32)      0           tf_op_layer_AddV2_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_3 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Mul_8[0][0]          \n",
      "                                                                 ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_6 (Tensor [(None, 32, 100)]    0           tf_op_layer_Add_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_12 (TensorFlowO [(None, 100, 32)]    0           tf_op_layer_Add_3[0][0]          \n",
      "                                                                 tf_op_layer_Add_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_3 (Te [(None, 100, 100)]   0           tf_op_layer_Add_3[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_6[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_13 (TensorFlowO [(None, 100, 32)]    0           tf_op_layer_Add_3[0][0]          \n",
      "                                                                 tf_op_layer_Add_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_6 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_12[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_14 (TensorFlowO [(None, 100, 100)]   0           tf_op_layer_BatchMatMulV2_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_7 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_13[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_6 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sum_6[0][0]          \n",
      "                                                                 tf_op_layer_Mul_14[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_7 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(3,)]               0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_6 (TensorFlow [(None, 100, 100)]   0           tf_op_layer_Sub_6[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_7[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_3 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_AddV2_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_3 (TensorFlow [(None,)]            0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2_3 (TensorFlo [(None, 100, 8), (No 0           tf_op_layer_Neg_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 1, 1, 1)]    0           tf_op_layer_Range_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 100, 7)]     0           tf_op_layer_TopKV2_3[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_6 (TensorFlowO [(None, 100, 7, 1)]  0           tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_11 (Tens [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_12 (Tens [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo [(None, 100, 7, 2)]  0           tf_op_layer_Tile_6[0][0]         \n",
      "                                                                 tf_op_layer_ExpandDims_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_7 (TensorFlowO [(None, 100, 7, 32)] 0           tf_op_layer_ExpandDims_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_3 (TensorF [(None, 100, 7, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "                                                                 tf_op_layer_concat_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_7 (TensorFlowOp [(None, 100, 7, 32)] 0           tf_op_layer_GatherNd_3[0][0]     \n",
      "                                                                 tf_op_layer_Tile_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_7 (TensorFlo [(None, 100, 7, 64)] 0           tf_op_layer_Tile_7[0][0]         \n",
      "                                                                 tf_op_layer_Sub_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv0 (Co (None, 100, 7, 64)   4096        tf_op_layer_concat_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn0 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act0 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv1 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn1 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act1 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_13 (Tens [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv2 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_conv ( (None, 100, 1, 64)   2048        tf_op_layer_ExpandDims_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn2 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_bn (Ba (None, 100, 1, 64)   256         ParticleNet_EdgeConv1_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act2 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_5 (TensorFl [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_4 (TensorFlowO [(None, 100, 64)]    0           ParticleNet_EdgeConv1_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_7 (TensorFlow [(None, 100, 64)]    0           tf_op_layer_Squeeze_5[0][0]      \n",
      "                                                                 tf_op_layer_Mean_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_act (A (None, 100, 64)      0           tf_op_layer_AddV2_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_15 (TensorFlowO [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_act[0][0\n",
      "                                                                 tf_op_layer_Cast_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_5 (TensorFlowO [(None, 64)]         0           tf_op_layer_Mul_15[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          8320        tf_op_layer_Mean_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            258         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,698\n",
      "Trainable params: 25,926\n",
      "Non-trainable params: 772\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "import os\n",
    "save_dir = 'model_checkpoints'\n",
    "model_name = '%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "progress_bar = keras.callbacks.ProgbarLogger()\n",
    "callbacks = [checkpoint, lr_scheduler, progress_bar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-04 21:59:56,558] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      0/Unknown - 0s 0s/sample - accuracy: 0.5227 - loss: 0.6905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-04 21:59:57,579] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5c67c469b30c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_finalize_progbar\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mnumdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'%'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumdigits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd/%d ['\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "# train_dataset.shuffle()\n",
    "model.fit(train_dataset.X, train_dataset.y,\n",
    "          batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "          epochs=1, # --- train only for 1 epoch here for demonstration ---\n",
    "          validation_data=(val_dataset.X, val_dataset.y),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
